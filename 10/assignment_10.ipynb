{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with non-linear features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import ticker, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of point in train data =  (500, 2)\n",
      "shape of point in test data =  (500, 2)\n",
      "shape of label in train data =  (500,)\n",
      "shape of label in test data =  (500,)\n",
      "data type of point x in train data =  float64\n",
      "data type of point y in train data =  float64\n",
      "data type of point x in test data =  float64\n",
      "data type of point y in test data =  float64\n"
     ]
    }
   ],
   "source": [
    "fname_data_train    = 'assignment_10_data_train.csv'\n",
    "fname_data_test     = 'assignment_10_data_test.csv'\n",
    "\n",
    "data_train          = np.genfromtxt(fname_data_train, delimiter=',')\n",
    "data_test           = np.genfromtxt(fname_data_test, delimiter=',')\n",
    "\n",
    "number_data_train   = data_train.shape[0]\n",
    "number_data_test    = data_test.shape[0]\n",
    "\n",
    "data_train_point    = data_train[:, 0:2]\n",
    "data_train_point_x  = data_train_point[:, 0]\n",
    "data_train_point_y  = data_train_point[:, 1]\n",
    "data_train_label    = data_train[:, 2]\n",
    "\n",
    "data_test_point     = data_test[:, 0:2]\n",
    "data_test_point_x   = data_test_point[:, 0]\n",
    "data_test_point_y   = data_test_point[:, 1]\n",
    "data_test_label     = data_test[:, 2]\n",
    "\n",
    "data_train_label_class_0    = (data_train_label == 0)\n",
    "data_train_label_class_1    = (data_train_label == 1)\n",
    "\n",
    "data_test_label_class_0     = (data_test_label == 0)\n",
    "data_test_label_class_1     = (data_test_label == 1)\n",
    "\n",
    "data_train_point_x_class_0  = data_train_point_x[data_train_label_class_0]\n",
    "data_train_point_y_class_0  = data_train_point_y[data_train_label_class_0]\n",
    "\n",
    "data_train_point_x_class_1  = data_train_point_x[data_train_label_class_1]\n",
    "data_train_point_y_class_1  = data_train_point_y[data_train_label_class_1]\n",
    "\n",
    "data_test_point_x_class_0   = data_test_point_x[data_test_label_class_0]\n",
    "data_test_point_y_class_0   = data_test_point_y[data_test_label_class_0]\n",
    "\n",
    "data_test_point_x_class_1   = data_test_point_x[data_test_label_class_1]\n",
    "data_test_point_y_class_1   = data_test_point_y[data_test_label_class_1]\n",
    "\n",
    "print('shape of point in train data = ', data_train_point.shape)\n",
    "print('shape of point in test data = ', data_train_point.shape)\n",
    "\n",
    "print('shape of label in train data = ', data_test_label.shape)\n",
    "print('shape of label in test data = ', data_test_label.shape)\n",
    "\n",
    "print('data type of point x in train data = ', data_train_point_x.dtype)\n",
    "print('data type of point y in train data = ', data_train_point_y.dtype)\n",
    "\n",
    "print('data type of point x in test data = ', data_test_point_x.dtype)\n",
    "print('data type of point y in test data = ', data_test_point_y.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAI4CAYAAABndZP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dfZRnVX3n+8+3i2qx4lOoxoBAV0vk3mtQujWtyPUudYlZONwZHdGIUEF7JtqLZoJGE+/SNFcdY98wc125GUMM08Yn/NUkxjyMmOBiTEhWjHck07B8AAnhsR8EI3ZfoElrwO59/zi/H/2rX53nx332eb/WqlVVvzp1zj7n7LP39+yz9z7mnBMAAEBI1nWdAAAAgLoR4AAAgOAQ4AAAgOAQ4AAAgOAQ4AAAgOAQ4AAAgOAQ4ACQmT1mZmeGsp2U7d9uZq+qaV1/bWZvr2NdAOpHgANAzrmnOefuzbOsmTkze17T25nZ5qbxdk8os92p7Z/tnPvrKusow8zuN7PXtL1dYMgIcAAEoWrwAyAsBDhAIMatBO83s++Y2f9nZp82sxOn/v4OM7vbzA6Z2fVm9pypvz3ZKmNmnzGz3zGzPzezw2Z2s5n99PhvfzP+l2+OHzddbGYbzOzPzOzh8bq/amaxZUve7cSYbPfh8XbPM7NtZvY1M/t/zOyQpA+Z2U+b2U1mdtDMfmBmK2b2rJlj9Jrxzx8ysz80s+vG27/dzLamHN+fM7O/N7NHzOwaSTb1t8TtmtnnJG2U9KVx2v+P8edfMLPvjdf3N2Z2dtK2ARRHgAOEZVnSBZJ+WtL/JOkqSTKzV0v6DUlvlnSqpL2S/iBlPZdI+veSflLS3ZJ2SZJz7hXjv28eP276vKRfkXRA0smSfkrSr0nK+w6Y2O3EmGz3WePt/vfx7+dKulfSs8f/a+P9fI6k50s6Q9KHUrb/OkXH4VmSrpd0TdxCZrZB0h8rOp4bJN0j6eXTiyRt1zl3maR9kv7VOO3/cfw/X5Z01jjtt0paSUkngIIIcICwXOOc2++cO6Sowr9k/PmypE855251zv2zpPdLOs/MNiWs50+cc3/nnPuxoop3S8o2n1AUNC05555wzn3V5X/JXZHtxHnAOffbzrkfO+d+6Jy72zn3FefcPzvnHpL0m5JemfL/f+ucu8E5d1TS5yRtTljuQknfcc79kXPuCUm/Jel7kz+W2K6cc59yzh0en48PSdpsZs/Mu+MA0hHgAGHZP/XzXkUtChp/3zv5g3PuMUkHJZ2WsJ7vTf18RNLTUrb5fytqfflvZnavmb2vQHqLbCfO9P7KzJ5tZn9gZt81s0cljRS1uOTd/okJfXmeM72tcQD35O9Ft2tmc2Z2tZndM17+/vGf0tIKoAACHCAsZ0z9vFHSA+OfH5C0NPmDmf2EpEVJ3626wXErxK84586U9K8kvcfMzq+63tnN5Pz8N8afneOce4akX9BUX5kKHtTUsTUz0+pjnbXd2XReKun1kl4j6ZmSNk1WXUNaAYgABwjNvzOz083sJEV9YT4//vy/SPo3ZrbFzJ4i6f+SdLNz7v4S2/hHSU/OZWNm/9LMnjeu9B+VdHT8VaeHJB2b3m6Cp0t6TFFn5NMkvbem7f+5pLPN7KJxC887JZ1SYLurjtl4+X9W1Iq2oOh8AKgRAQ4Qlv8i6b8p6nh7r6SPSJJz7i8l/Z+KOso+qKgT8ltKbuNDkj47HjX1ZkUdZf9CUQX/3yV9vO65ZpxzRxT1KfraeLsvS1j030t6saRHFAUlf1LT9n8g6eclXa0oKDlL0tcKbPc3JF01TvuvSrpO0SPD70r6jqSv15FOAMdZ/r6AAHxmZvdLertz7i+6TgsAdI0WHAAAEBwCHAAAEBweUQEAgODQggMAAILj7cvpNmzY4DZt2tR1MgAAgMduueWWHzjnTp793NsAZ9OmTdqzZ0/XyQAAAB4zs71xn/OICgAABIcABwAABIcABwAABMfbPjgAAITiiSee0IEDB/SjH/2o66T01oknnqjTTz9d8/PzuZYnwAEAoGEHDhzQ05/+dG3atEnRe2lRhHNOBw8e1IEDB/Tc5z431//wiAoAgIb96Ec/0uLiIsFNSWamxcXFQi1gBDgAALSA4KaaosePAAcAAASHAAcAgIH60Ic+pI9+9KNdJ0POOb3zne/U8573PJ1zzjm69dZbK6+TAAcAAM+srEibNknr1kXfV1a6TlGzvvzlL+uuu+7SXXfdpd27d2vHjh2V10mAAwCAR1ZWpO3bpb17Jeei79u3Vw9yrrvuOp1zzjnavHmzLrvssjV//8QnPqGXvOQl2rx5s974xjfqyJEjkqQvfOELesELXqDNmzfrFa94hSTp9ttv10tf+lJt2bJF55xzju66665KafviF7+ot771rTIzvexlL9PDDz+sBx98sNI6GSYOAIBHdu6UxrHFk44ciT5fXi63zttvv127du3S1772NW3YsEGHDh1as8xFF12kd7zjHZKkq666Sp/85Cd15ZVX6sMf/rBuvPFGnXbaaXr44YclSddee63e9a53aXl5WY8//riOHj26Zn0XX3yx7rzzzjWfv+c979Fb3/rWVZ9997vf1RlnnPHk76effrq++93v6tRTTy23wyLAAQDAK/v2Ffs8j5tuuklvetObtGHDBknSSSedtGaZ2267TVdddZUefvhhPfbYY7rgggskSS9/+cu1bds2vfnNb9ZFF10kSTrvvPO0a9cuHThwQBdddJHOOuusNev7/Oc/nzt9zrk1n1UddcYjKgAAPLJxY7HP83DOZQYM27Zt0zXXXKNvf/vb+uAHP/jknDPXXnutPvKRj2j//v3asmWLDh48qEsvvVTXX3+9nvrUp+qCCy7QTTfdtGZ9F198sbZs2bLm67rrrluz7Omnn679+/c/+fuBAwf0nOc8p/wOixYcAAC8smtX1Odm+jHVwkL0eVnnn3++3vCGN+jd7363FhcXdejQoTWtOIcPH9app56qJ554QisrKzrttNMkSffcc4/OPfdcnXvuufrSl76k/fv365FHHtGZZ56pd77znbr33nv1rW99S69+9atXra9IC87rXvc6XXPNNXrLW96im2++Wc985jMrPZ6SCHAAAPDKpJ/Nzp3RY6mNG6Pgpmz/G0k6++yztXPnTr3yla/U3NycXvSiF+kzn/nMqmV+/dd/Xeeee66Wlpb0whe+UIcPH5Ykvfe979Vdd90l55zOP/98bd68WVdffbVGo5Hm5+d1yimn6AMf+ED5xEm68MILdcMNN+h5z3ueFhYW9OlPf7rS+iTJ4p57+WDr1q1uz549XScDAIDK7rjjDj3/+c/vOhm9F3cczewW59zW2WXpgwMAAIJDgAMAAIJDgAMAAIJDgAMAAIJDgAMAAIJDgAMAAIJDgAMAwEB96EMf0kc/+tGuk6G///u/13nnnaenPOUptaWHAAcAAN+srEibNknr1kXfq75K3HMnnXSSPvaxj+lXf/VXa1snAQ4AAD5ZWYne1bB3r+Rc9H379spBznXXXadzzjlHmzdv1mWXXbbm75/4xCf0kpe8RJs3b9Yb3/hGHRm/K+ILX/iCXvCCF2jz5s16xSteISl6O/lLX/pSbdmyReecc47uuuuuSml79rOfrZe85CWan5+vtJ5pvKoBAACf7Ny5+kVUUvT7zp2l39dw++23a9euXfra176mDRs26NChQ2uWueiii/SOd7xDknTVVVfpk5/8pK688kp9+MMf1o033qjTTjtNDz/8sKToBZzvete7tLy8rMcff1xHjx5ds76LL75Yd95555rP3/Oe9+itb31rqf0oggAHAACf7NtX7PMcbrrpJr3pTW/Shg0bJGnNizYl6bbbbtNVV12lhx9+WI899pguuOACSdLLX/5ybdu2TW9+85t10UUXSZLOO+887dq1SwcOHNBFF12ks846a836irxsswk8ogIAwCcbNxb7PAfnnMwsdZlt27bpmmuu0be//W198IMf1I9+9CNJUWvNRz7yEe3fv19btmzRwYMHdemll+r666/XU5/6VF1wwQW66aab1qzv4osv1pYtW9Z8XXfddaX3owhacAAA8MmuXVGfm+nHVAsL0eclnX/++XrDG96gd7/73VpcXNShQ4fWtOIcPnxYp556qp544gmtrKzotNNOkyTdc889Ovfcc3XuuefqS1/6kvbv369HHnlEZ555pt75znfq3nvv1be+9S29+tWvXrW+rltwCHAAAPDJpJ/Nzp3RY6mNG6PgpmT/G0k6++yztXPnTr3yla/U3NycXvSiF+kzn/nMqmV+/dd/Xeeee66Wlpb0whe+UIcPH5Ykvfe979Vdd90l55zOP/98bd68WVdffbVGo5Hm5+d1yimn6AMf+EDptEnS9773PW3dulWPPvqo1q1bp9/6rd/Sd77zHT3jGc8ovU5zzlVKVFO2bt3q9uzZ03UyAACo7I477tDzn//8rpPRe3HH0cxucc5tnV2WPjgAACA4BDgAACA4BDgAALTA1y4hfVH0+BHgAADQsBNPPFEHDx4kyCnJOaeDBw/qxBNPzP0/jKICAKBhp59+ug4cOKCHHnqo66T01oknnqjTTz899/IEOAAANGx+fl7Pfe5zu07GoPCICgAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABKdygGNmZ5jZX5nZHWZ2u5m9K2aZV5nZI2b2jfHXB6puFwAAIEkd76L6saRfcc7damZPl3SLmX3FOfedmeW+6pz7lzVsDwAAIFXlFhzn3IPOuVvHPx+WdIek06quFwAAoKxa++CY2SZJL5J0c8yfzzOzb5rZl83s7IT/325me8xsD6+UBwAAZdUW4JjZ0yT9saRfds49OvPnWyUtOec2S/ptSf81bh3Oud3Oua3Oua0nn3xyXUkDAAADU0uAY2bzioKbFefcn8z+3Tn3qHPusfHPN0iaN7MNdWwbAABgVh2jqEzSJyXd4Zz7zYRlThkvJzN76Xi7B6tuGwAAIE4do6heLukySd82s2+MP/s1SRslyTl3raQ3SdphZj+W9ENJb3HOuRq2DQAAsEblAMc597eSLGOZayRdU3VbAAAAeTCTMQAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDhColRVp0yZp3bro+8pK1ykCgPac0HUCANRvZUXavl06ciT6fe/e6HdJWl7uLl0A0BZacIAEfW4B2bnzeHAzceRI9DkADAEtOECMvreA7NtX7HMACA0tOECMvreAbNxY7HMACA0BDhCj7y0gu3ZJCwurP1tYiD4HgCEgwAFi9L0FZHlZ2r1bWlqSzKLvu3f34/EaANSBAAeIEUILyPKydP/90rFj0XeCGwBDQoADxKAFBAD6jVFUQILlZQIaAOgrWnAAAEBwCHAAAEBwKgc4ZnaGmf2Vmd1hZreb2btiljEz+5iZ3W1m3zKzF1fdLgAAQJI6+uD8WNKvOOduNbOnS7rFzL7inPvO1DL/QtJZ469zJf3u+DsAAEDtKrfgOOcedM7dOv75sKQ7JJ02s9jrJV3nIl+X9CwzO7XqtgEAAOLU2gfHzDZJepGkm2f+dJqk/VO/H9DaIEhmtt3M9pjZnoceeqjOpAEAgAGpLcAxs6dJ+mNJv+yce3T2zzH/4tZ84Nxu59xW59zWk08+ua6kAav0+S3hAIB8aglwzGxeUXCz4pz7k5hFDkg6Y+r30yU9UMe2gSImbwnfu1dy7vhbwgly+o2gFcCsOkZRmaRPSrrDOfebCYtdL+mt49FUL5P0iHPuwarbBorq+1vCsVZS0HrFFQQ9wJDV0YLzckmXSXq1mX1j/HWhmV1uZpePl7lB0r2S7pb0CUlX1LBdoLC+vyXcp5YKX9KSFLRee209LXW+7CeAYsy5NV1hvLB161a3Z8+erpOBwGzaFFV2s5aWohdS+mzSUjFdmS8sdPOOLJ/Ssm5dFMTkUfQ8+7SfAOKZ2S3Oua2znzOTMQalz28Jz/N4ra3WBp8e9W3cmH/Zoi11Pu0ngGIIcDAoed8S7uNjiazHa212oE5Ky9697R+3uKDV4sZtqlgwJPX/kSYwZAQ4GJzl5egxxbFj0fe44MbHkVZJlfPk8zZbG5LSYtb+cYsLWi+/vJ6WuqxjDsBfBDjADF8fS2Q9XmuztSGp1WS2L0xbx202aP34x/O11GXp8yNNYOgIcIAZXT2WyHoslvV4rc3Whum0SNLcXHJH364e52S11OVdRx2BEoD2EeAAM7p4LJH3sVhapV2ktaGOPkbLy8e3efRo8nJ9f5xTR6AEoH0EOMCMLh5L1PFYrEgH6rr6GMWlexqPcwB0hQAHmNHGY4nZFpS4uXmk4o938rQ21NnHKC19eY6bj6PVAISBAAeIMR0o7NoVVf6zlXDZyjmuBaWuYc151NnHKCl9kwn1soIbH0erAQgDAQ6QIu09R2Ur57gWFOfWBjlNPd6ps49Rlcd5vo5WAxAGAhwgRVIlvHt3+co5qaXEufoei6W1LtXZx6jK4zwm0QPQJN5FBaQo8p4jKarkjx1LX6bp92HleX/SykoUjO3bF7Xc7NrV/uigPr8XDIA/eBcVUELSY5u5uWLLT2t6lFaeRz8+DH1mEj0ATSLAAVIkVcLbt5evnJsepdWXRz9MogegSTyiAjJMHudMRjtNLpmnPU16ylOkQ4e6e8wTJ++jHx8eUwFAVTyiAkqazNg7P7+6P85jj0mHD0uf+5xfM9zmefTDEG0AoaMFB8ghbTI+HzvFZrXO0MEXQCiSWnAIcIAc0kZT5Rk55Zuk/enjvgAYNh5RARWkjY7q48sku3ihKAC0iQAHyGHSB2fW+vX9HNbMEO1u8Q4uoHkEOEAOy8vSpz8tLS4e/2xxUfrUp/zpXFwEQ7S7QwdvoB0EOEBOy8vSD34QVUqjUTRM/LLL+nEHHtdi4MNkf0PEO7iAdpzQdQKAvpl9FcLkDlzyM0joW3pD15eJGIG+YxQVUFDfhlj3Lb2h43wA9WIUFVCTru7Ay3ZMpcXAL3TwBtpBgIOgtDE6pYsh1lU6pjIk3C908AbaQYCDYLQ1OqWLO/AqHVNpMfAPHbyB5hHgIBhtjU7p4g68ymMmWgwADBEBDoLRZl+TuDvwJh+PVX3MRItBvzARIFAdAQ6C0WVfk6YfjzXxmKnOSnRIFXLT+8pEgEBNnHNefv3sz/6sA4oYjZxbWHAuqhair4WF6POmLS2t3u7ka2mpvm2MRtH6zKLvVfarzmPV5XFvWxv72kZeAkIiaY+LiSOYBwdBWVmJ+tzs2xe13Oza1c7jmL69nbvOuViqrKur81VWG3PY9C0vAV1LmgeHAAeoQd8mb6uzEi27rtkZlqXosZvPHaDbCD42bJAOHlz7ua95CegaE/0hSL70/ejbUOw6+yuVXVcf38nUdD+vlRXp8OG1n8/P+5uXAF8R4KC3fOqM2beh2HUGZGXX1ccZlpsOZHfulB5/fO3nz3iGv3kJ8BUBDmrVZouKby0AfRqKXXdA9tSnHv95cTHfuvo4w3LTgWxScHfoUD3rB4aEAAdPqhqctN2i0scWAJ+UDcim88mGDdK//ber+4z88If51nPhhVGQMM3nx3oTTQayfQz6AF8R4EBSPcFJ2y0qVAbtm80nBw+ufaSS55yvrEif/ezqDrtm0tvedjxg8KV/VZv61pcL8BmjqCCpnlFAbQ9v7eMonL5Lyiezss55Vn4b8rnt29B5oGsME0eqOoKTLoZKUxm0KymfzMo651n5rW/D7gF0h2HiSFXH454umtf71LE3BHnyQ55znpXf2u5flfY4bIiPyoAQEOBAUj3BSd+GSqO4uHwyPx+NnCpyzrPyW5v9q9L6n/k0FQGAguLe3+DDF++ial+d7zpCuOrKJ2nryXrnU515Ne3dT7wXCvCfeBcVgD5J6l9VdwfktP5AEu+FAnxHHxwEjX4Sw1H3dARpj8OYigDorxO6TgBQ1ewd/aSfhET/n75KO6d1d0DetSu+RWjSHyjtbwD8RQsOes+3VzagurRzWnerSlrn+OXlaPLBublo2bm51ZMRAvAXAQ56r8odPY+2mlH1uKad0yamI0iabmAy4/LRo9HvR49Gv5NPkInCpXMEOOitSfmR1E8+646eIcDNqOO4prXStDkdAa2DKIXCxQuMokIlXc0kHDeSZlqeUTXMltuMOo6rL69qaPv1IwgEhUurGh1FZWafMrPvm9ltCX9/lZk9YmbfGH99oI7toltd3qTE3VlP5L2j523k1SS1wNdxXH2ZNJJRVCiFwsULdT2i+oyk12Ys81Xn3Jbx14dr2i461GXzfVI5YZb/lQ2+Vl51PrrPWlfZbaUFtyedFP8/SZ8nqes1HFWOJ2/3Rim+Fi5DEzf7X5kvSZsk3Zbwt1dJ+rMi62MmY/+Zxc/yatb8tuuYYTZrttwu1JmmPLMBl91W2vFfXIz/2+Ji8X1I2q+8sxjXcTyZ4RuF+Vi4BEwJMxm3GeAclPRNSV+WdHbCctsl7ZG0Z+PGjY0fFF/1pUDtchr7usoP3451ncc0a11VtpUW3DYZ+BY977xqYS3f8nywONCt6TrAeYakp41/vlDSXVnrG2oLTp8C/67TGmL5UWdwkLWuKtuq8v6mKuctad2T9c+uq8tWRh91fc0CTeg0wIlZ9n5JG9KWGWqA07c7zhCDjDoVPT59acFJqyjL/i2PpIAlaV1J+1jX47K+6Vv5AuTRdQvOKTo+JP2lkvZNfk/6GmqAwx1nOMpU5n3pgzP5/7jgbTRa3Q9ncfH436pWsGktOHHrGo2cW79+7TLz88MMxilfEKJGAxxJvy/pQUlPSDog6RclXS7p8vHff0nS7eM+OF+X9L9mrXOoAQ53WOEoey7rbBXLWlfdLXBZQVPVCjZu/VnrSur0PMRrivIFIWq8Bafur6EGOGXv+nlM5J8h3i03+VhsYpLf87TgOJf+WGto1wp9cBCipACHVzV4pugEZ8wI7u8rX4Y4FUbW/GZ1zCszmR9nNMq3rrTjPbRrJU/54uv1BBQWF/X48DXUFpyiht7k7PMdqc9pKyxnM2Ge/NjmI7jJMmmPtYZyreQRVJ7FYIgWnDANfUbwMrMpV5m9t8j/+fK6gcoKNBPmaaGZnaFYarbFYHIekgzlWsmDl4siKHFRjw9ftODkM/QWnKL9XOLuUM2c27EjfTuDvrMtmMnammmYSf/qN8R+Y+g/0ck4TIOueF1ypTU3F1/BJi1vln7MOqkcSzzLaaTDeYO1XpXjWvR/h36t5EEQiD4iwAlYW6OofBytlWfYcJ5hylmFeOt3tiVq46bmtWmy1qtyXLPOZVw+bXvYfN8QBKKPCHBQSdMFX5WKZfp/5+bS6+K04cVplWrrd7YJG9w/t9TII5jU85vz5Jc5h0204MwGPk098grV0IM89A8BzsDUXUg1WcHXWbFktQiMRsnLpO1L65VfQiKPyhK329S7pZxzmRmq7PGpuw9OWotO5WMAwEsEOAPSRGXc5COaNt+/5FzUobjMXX6rd7YJO3KflhKPTZXjWPX8Vm09qtp6F9dyk7Yfcdukgy3QTwQ4A9LEnWiTd7d1Vix5gzvvm+FjduQxLbhLNEo8NlUC26rnt+vgIOsdVbPz8MQdJ17pAPQTAU7PFamQm6hsmnxEU3fw5H3wktdo5PbPLbmjMneflp4MbtKOTdl9r3p+23q8k7R/aa03Rd4wTh8coH8IcHrMl/k+mgoc6NyZrM1jU/VRUdPpTNtG2nQBs2lIuwEIJjgGBoQAp8eGMN/Hjh3HR0DNzWVPvJckxAqqjn1q47g0vY2066BIng+tM3GIeR4oggCnx5qY78MndQVkTQV2o9Hq/hmLi34fz1mdBLw1Z8DRKPkamB4hl2eTfbwBSBLSvgBlEeD0WN3zfTQhT+WSFCjUdUfdxJ35aOTc/Pzada5fX+1YtxmAtt5iUXOtmzUcvMx+9OkGIE1orVFAGQQ4PVb3fB9tpG+2PhuNoqBgNr1xwcPsnXleTXSuThudU6UTdJt33a2PcEqpdeucDLDroN4HXY9eA3xAgNNz0xVD0nDWOgq2Oiug6QAgrZLKmn04rybuZovMrdJlOn3aXtJBOzaepLBogJJ2DoYc3DhHCw7gXHKAs66LN5ijuOVl6f77pWPHpKc9LXm5jRvLb2NlRdq+Xdq7Nyom9+6Nfl9ZSf+/ffuyP09aRpKOHpUWFlZ/trAg7doVbXvTJmnduuh7Wlp27UpeT1lpx7Pssc5zvOrUxHFJlXBgvju3UUeOrP7syBFp585Sq9PSUnRdzCqSZ7pWNa2tn1ugT+KiHh++aMFJ1tQdbdm7waotOJOWotmWozKPcuruW9FEH5w8x6JurfY5SThxl07N41OkJaxIPuhTp9s6O9eH0J+olzj4XhCPqMKRNlFZFWWf51ftg9P2fD5F1T2KKqtPla8VciExBX8br3PwJc/k0ae0IkafounAEeAEJG9A0URfmrQ0lR1FlSTkDpRpo8dCreTaqA/6lGf6lFbEIEItp4FWLwKcwKTlkbIViW83JEMoP4ZWyXU5GWAVTaR7CPk7aEO7eOvQUCVDgDMgbTwKaINvAVcTuq7kfDrfdWgizzQ5gWTo+TtoXV+8fdTQMSPA8UyTFUtINxahVcCzuqzkQq1g684zTdZjoefvoIV6ATWpocqJAMcjTV8XZQrkIRe0s/u+Y0ezx6Kx7RU8idyA5uP7DUPRa3fI13rt6jqYQzkptOCEH+A0XbGkBVBlh2OHev3lmSW6zuCzseC2xIp9r7h94XMgWPS0153/Qi0XWjWkliD64IQf4LAqlFsAACAASURBVLRRsRQJZJJmRp4U4CFff2kjmZqozBqrLEusuE8dcrvkc/4veg7rPOc+H5de8TmCbgKjqMIOcLrIz6NR8isRkr4mAVfI11/apIlNBJ+NBbclVtxVh9w+BkBdpzlp+0VPe535L+RyoVVVJiDr24XUEAIcj7R955PnMUxaQRXyo4y+t+BMyrj7VG7FbXfIzZX3KbhXSTtmXbbghFwutKpsp0maz55EgOOZNsvwrEp8cTH9Wgn5Tq3PfXCm13WJRu4xFeh41ZCsSi8zLw204E47RWnHrMs+OCGXC60qc1I4+KsQ4AxY2mOYpDpwemTP4uLa9zGFVOd0PYoq7/pn/2+279QlGrn7tOSOamrFO3aszQANnryscjfzrn+ABXdW/ZZ1zLoaRTXQWLQZRU8KzWerEOAMWFKdMTcXfx3FFVzr10cVKk8NulHkMeOTZdxolFwQNhQwZFV6mfHLAAvurGPic8zH08SO+JwpOkCAM2BF77TquHYo+OqVt6/QqvOU9k8NBgxp5z4zLxbIfKHksTwtNGVfvRLC8UGMvjSftZQJCXAGrkg+S3uklXdbfbj2ChsfxGMyt39uyV2qUeMVR1pH0rivVcc57UR2eKeXmhdzZp6Q8liemK7MY6hQjg8S+B7BtpgJCXCQW1KBa5YvbwbZehpzsT6mBXeJRo1VHHkeSy0uppRxVU9kV3IU3CHlsSbqgZCOD3qqxUxIgNMCXwLqqumo2nUjyG4UCRfrfVpqrOLIarnJrATjak6zqONxE3JkvLqukTJ5zJfrM07daQvyGkS/tJgJCXAa5kuTcF3pSKpU8+TNIO8eEy7Wo7LGKo6sJ0y5zmlbtXqOjNflEGVfrs886jhlQV6D6BdacMIJcHwpUOpKR5X19Kkyyc2jFhwvK6kcia1zf7roON+Guq6dIK9B9At9cMIJcHxpEq4rHVXzZpMNB508ami4D07cPvlaScUe/xwZr+5rpI6O8749sqk7CPT1kRwGglFUYQQ4vtwhhl5AdlrpNzSKKm2ffDsHSWk9vLiUmfG6zJu+XJ9Z+hKIIUC+FTYFEOA0zJe7bV/S0ZS+VFRF9GmfktJ65WJ7fXDKrKcv10Wf8gJK8DWI6MsFkoAApwW+5F1f0tGEEO9w+7RPqWltaBTV7P/MvqIibxDQh+ui5/UM0vh8cnseWRPgIAh9uQ6LVKZ92Sfn2k9rnrmAfA4Iy+hDIOYl3w+czxd6n+6yYiQFOOsE9MiuXdLCwurPFhaiz32xsiJt3y7t3RuVEnv3Rr+vrMQsuGmT7tu7Tnttky7R8QV826eJto//zp3SkSP5lt24sZk05DU+nVq3Lvq+5nzntLws3X+/dOxY9H15ub40Biv3RdehffuKfd6mpIun64uqqriox4cvWnDK8f0mpg6+72OuG7WYpol/soVWXv9QVZsj5PK03EjRy2C7PGY+P30YBJ9bRyZ8TmPPM7B4RBW+nufRVXwPYtLkau1NmVdnaSmabLiv+19W0sTLeQKc+fluj5HPddcg9OERi+8FdI8L3UEGOD0+X6WEUsj6Xg5kyXUeMmZGnv0qu/95rwEfrpWk4zZ7qKq8RqQpfahfy/Ihb2TqS+HXi4PZP4MLcPpeSZYRSiHbl7IqSa68lzEzch37n/ca8OVayXo1RdZjqy7zed/zbBJf8kam3iQUTRhcgBNqgZOm6j77cnMRQqCWeSxTZkZOrcALnKS8+cGXa6Vv6Z0Wav3q47FO5EsBhtYNLsDpcyVZ9jqtUsj6VED3qlCtYnyij8rcfVpKDW6kfJPpTct7DfhyrRRpcZqfX71c131wJukqW7/6Wjf7kjeANIMLcPpaSVYNNMoWlD4dL5+CrTbkmesl7+sQpvWxRSRP/h2NolFT02ntehRVFU3k97oCJp/yBlz8ifU1Om5RowGOpE9J+r6k2xL+bpI+JuluSd+S9OKsdQ61D05XBYpvd2pDu2Zn9zd2FFXBk+RLH5y6z2VolW7d+1Pn+exrORqkuJMxP7822h/gCWo6wHmFpBenBDgXSvryONB5maSbs9Y51FFUXQUafak0fDunraanxEnqehRVExWkb8F4VXXvTxMBk0/X3GAVmRjKt4K7YY0/opK0KSXA+c+SLpn6/U5Jp6atb6jz4HQVaPThTs23NLaeHt8OQA5N5Oe0cr6PFXDdxyi0ABBjeSeFGuDJTgpw2npVw2mS9k/9fmD82Spmtt3M9pjZnoceeqilpPmlq1cRLC9Lu3dLS0uSWfR9926/pomPm7b/yJHo80Gkpw8naUYTs9PHXSMTPs7Qn6Xuaz7UWfcHr8gJ5GRH4qKeMl9Kb8H5c0n/29TvfynpZ9PW13ULTpfNsjQJx/PtztSb9BTJMC1nrqZaJCe70VULfd2Hsc719bChD3nQByeReESVHwVEN7IKed/6CXmRniKZtYOM3fQm6wwyi/RX8r184CYpUIyiitV1gPO/a3Un47/LWl+XAU7bFRf5M1+l4VvF4kV6imTWBjP2V3eM3P65aE6f/XNL7qs7jh+EJvN3XbtU5Fx6Edh2KKjyKqidaZDnx6nRAEfS70t6UNITivrX/KKkyyVdPv67SfodSfdI+rakrVnr7DLAafPRgxeVpAfyVhq+XWedp6dIZm0oY391x8g9prWzMk8HOU2p6/opErR482iyA0GVV0HtTIN6cJySAhyL/uafrVu3uj179nSy7U2bos6Ks5aWpPvv7++2fLZuXXTlzDKTjh1rPz29USQDNZTZDpywSacfXbveA3NLOv3H5deb18pK1LF7376ob+WuXcX7XRfJf0O+ZoPa96B2pkE9OE5mdotzbuvs522NouqVNkcyNTHKpIiVlSj/rlsXfe9q9AkjP0oqklkbytjPORqfWZM+r9vyclTOHjsWfS8zqKxI/utqpKMPui6vahXUzjSoz8cprlnHh6+hjKLq8nm+Ty2PPqWldzoeRbV/bik2E++fW6q87rYUzX+dP5osoY40B9X/qMrO9DEDlNWDk66hvYuqL7qs2H3Lt9NlxuJi9OVb+TGkci2vLvvg1Cnkc1tXORPUjUjZnQnqIOTQg/0lwPFYVwWrr50lfb2efE2XD9JGUXmpR9GMby0vPTp02crsjG93hm3w/KQT4GANX6/T4NLleeEwOD2KVOtKqq83M72U9soErvFOJAU4dDIeMF87S/rap61UulZWoncH7N0bFYF9fJdAaBLesXHgbTu9Oy11vQ6ETvw1SjtoWde4L6M6BoIAZ8B8fbWRr4VxqXT59gKtrvhUsCdEpM85us+72LNoUJ10mH29mZnlUzZJlPYytIm4a5ybnfbFNev48MUjquHy9QlCqXTxbKDSCW3k6V7Cs8b7tOTFo9BpRR6LZh3mpGPpyxNUX6/7WNMHLe1x1bQ8J9OXk9Ezog8O+sTX67xwunztUNSmksegsQovZsWPacFdopF3sWfTr5DwKajo7aWSN+FZNzs+nYyeIcBBr1QNcLwJkCi0SrdiNVrhjY6P+rpPS08GNz5WqHnzcpnDnHWM07Zd9zXW28bOvNd41sHubYTXPQIc9EbVmMC7mMKbaKsjJQvupis87/JJRWUOc9oxTjs+TRy7Xtfvea7xrIPW2wivewQ4HRl63VZG1YIu6f8n6+ActKxkbdhGhRfS9Rl3mCd1ZtK+pR3jsn+rM/19DjhjpWW4Xkd43SLA6UCXF2yfC+6qNzJp/f4yz0EDB67P56I2JQ7CICq8mk0O83Rwk3bs0o5x0vVj1lxjw6CvFTJ8aQQ4HagSkFe50Pt+naQdtzzHJa0FJ/UcNHDg+n4uujboCq+CoqOvZo/xaJQcxDTVggNHhi+JAKdhcfmy7F1O1Uqx74VP0v7v2JHvuMT9f65z0MCB6/u5QD9VaWEZjZybm0v+/6b64PQKgYhXCHAalHSxLy6Wq9yqVooh9FWLKz+KHM/ppvrcx7KBAxfCuUhVZ0E/s66v7hhRh5RUtgzJc3Mwvewgz8/gozv/EOA0KKkwWVwsdx1UrRRDbDXI6hOQ9n+5zwEtOMXUWdBnzE3TZR3Sx4q87KnJerwbRL6tKuiLukENXkgEOA3KGmpZ9JxWvX6S7sIWF/tROMcp3BozJfc56EEfHK8q2zoL+oR1TWYX7qoO6fPNepm8ktZBvy/73bi6m2W9uqgb0vCFRIDToLoD+jryQtIjnb4WUmkFb53789UdxyeA2z8XPSapqq7yy7vKts6CPmFdR2W11CFlDe1mPWl/5+b6WW40os5M4d1F3ZCGLyQCnAY1kUfrqBRDKpzTHgPWxfeyxrvzWVeCUnq1dt2CE3wfqhl13VwF3SBRZ0HR1UXd9klq+EIiwGmYjxd1WquHb2nN0kbw4V0AMcO7yrau2jChV6sPfXB8zxNNlDtDnqIit7oOfBcXdRcniRacfgc4PkrKU3kmAPPFdDmyuBh9NRWYeRdAzPCysq1a0Kc8E/FhFJXPFbaPafMyj/qsiwPWxTbpg0OAU7e4PJU2eVfTaSlaWbVdgPteOPtYoVXW1R1sgczYRutsF4MRmuD7TYJ3uriouzpJjKIiwKnbbJ6Ky9e+toi2XYA3XtbUcIH7+Ci0kuBOcntJ8jGY8DHo8l7bF3WAJ4kAB865frWI9uDmvtiKPatYvUAzXekkebgrZPM+CPAkEeC0xPc77D61iPpYgJcW1M7UrM2LxsNmj65e6dKUVk6n7wWt7wI7fgQ4LfC1wJnVlxbRvhzPXDysWAfJw0CzSpICq6fyCapgCEiHmZEApwUelp1eqFIeBVOAkzn84GHl6GGS/Ma15J+OMzEBTgu4SU8WTKBSFrVYfapmJg8zo4dJStZ1Yn0taLs+Ll3qOOgkwGkBNxZINBqtfndGn18M1iUCxW7FHP/HtOCuXBy1dwri3kFTpKBtanbEIefLjoPOpABnnVCbXbukhYXVny0sRJ+3ZWVF2rRJWrcu+r6y0t62kWBlRdq+XTp48PhnP/xhd+nxQdmMunOndOTI6s+OHIk+R/Nijv9P6Ijec3Cntm+X/vaKhguglRXp0UfXfr5+fb6CdnIt7t0bVcF790a/V01n3/Nl1Ypj48Zin7clLurx4auPLTjOddtKWfUmYigtrK3vJ017q1XJqL4+nhiIY0p+KeolGrl/so7ep5L3pXRNXYt9zpd1tD7RB2cYAU6Xqo7GyJs/+xwIdXId9rnwa0KVjEqw2JnRyLm9thR7/O/TkrtP8X+r9dxUvZaauhb7nC/rSjujqAhwmlTl2s2bx3fs6Ne7rGZ1Ug71ufBrQpWMOvS+Dh1aWnLuEo3cY1rbB+cSjdzRhNadWgP5qtdSU9din/NlADdgBDgDkNZ6mxVY58njo1F377KqSyfXcp8LvyZUrWT63ITok4LHcXLtXKKRu09L7qjM3aelJ9/4ntS6U2vhUMdz+Kauxb7mywBuwAhwBiDu2l2/3rn5+ezrOU8eT1qmT8F+Z9eyL4WfD+kg4OteiXOQdv0vLTn31R0tndcApwnoVADXIwHOQMxeu3lHVObJ40mtH30K9gO4lsvzaeepZLqVEK3cp6XE05Er+/h8Xn1OW9d6fmwIcAaqyCOZrDyedgc3CXL6cF30/Four63mq7YP8GBPaAUJBcNRWWrc29tD7VNw76venlwCnMGqs06LKyNmvygzPNZGB6S6K5KsQpeKq5yUFpzWW2VHI3d48XifnkYmDQygn0mjen4dEeAMVJP1zdwcZUavtFHINx1Rz2ZeKq5yEmYknnQYrjvuTUvHj05Ym45t8zUHOQGMFGpUz68jApwBa6rlkTKjZ9poXakzU+QpdItur8fN8LUbH4vZ0VBt1m2HF5diz9+kL1Btel6BN67nhTkBDmpHmdFDdVXwScFSUq/2ScYosr08hW6RTNjzZvimVDksVbNT0tw5R2X11q2c+3Q9L8wJcFA7yowBS5t0Ka2jVpEMkqfQLZIJe16IN6lMoFLH9Z80+3HtLTiTBOfZySG28vW8MCfAQSPylAVDLC+ClzZnwOJidktOHnkL3bwZrOfN8L6pI168cjF+ZuRL1eLbyaf1vKKvpMcFNQFOz/Q4r60y5PIiaFlzBqS14hQJKOq8EDxswenzdV5HvDgaObdtfvXMyJdq5HbsaC7dqTzMI8hGgNMjIQUFvSsvuqpx+lbT5ZkzwLdhdp5dWJ4lp7C6rm2vsj6tfL1EgJODLxda74KCFL0qL7qqcfpa000umCItOV3vly8Xuev/dd7XbJuq7ydloAhwMvh0sfYqKMjQq/Kiq8T26iDFSEu/RwGFbwpf5x4eSw+TVE1bFUFwB25KB/tGgJPBpzrGp7RU5VPgmKlKZFnlou57RNurk+yPQtd5zDH+J4s644ZWP3au6Qo65Oulo30jwMngUx0TWv7vzc1K2ciy6gnrS0SbdiJ7c5L9USjbJOSRyasVWisfOM/V9eV6L6OjfWs0wJH0Wkl3Srpb0vti/r5N0kOSvjH+envWOofcguMc5UgnygYqVTNPHyLaPqSxKA8ustxJyHg5ZitlVYh5oAt13U13kX+ztpm1bw2lubEAR9KcpHsknSlpvaRvSvqZmWW2SbqmyHqH3AcHHSpzAdY1XtbniDbvpHtl96Ht/Y+74CfnsUfHf/rlmFI3aQii5aFNdRzHLiqsPNvM6o/XUJqbDHDOk3Tj1O/vl/T+mWW8D3Cc87+OgaeGUPDnuTOrMt9/24V1ntFfPhUAMcco7uWYjSa5rbfRN93/petCvmp+H426mYIh701O0r41WE42GeC8SdLvTf1+2WwwMw5wHpT0LUl/JOmMrPUOeR6cvvChrPBC6M1/eQrUKoVXFwFi2kzMvgao4wvuWMLLMRtPctPnKe91lFXwJP3dpxFSZQvPuH1oKticlTfATdq3BgPkJgOcn48JcH57ZplFSU8Z/3y5pJsS1rVd0h5JezZu3Fh5p9Gc0Ov0wkKN9tIK1OkTXqXw6qKHf1YLTsPbr5pduqjfGr/oq7YQZP29jUC6q2PURoRb9fj1tAUn8xHVzPJzkh7JWi8tOH4bwlMZuOQTPTeX/9l72W00mZmy7oQb3H4ddWBn11+TgXxaq9pkm1VaEtMC6br2q+kTk3aMfOiD0+T/p2gywDlB0r2SnjvVyfjsmWVOnfr5DZK+nrVeAhy/+TSsHg0q0izdpz44k+2OK6RjWr2fT6xvbvt97WPauKQDk+dx4iQ/puXXpPUvLtZ3MJsuGPPecDSlaiDYt1FU0bp1oaR/GI+m2jn+7MOSXjf++Tck3T4Ofv5K0v+StU4CHL8NpgUn1EdPeRU50b6Nosq5ztFo7Qsft8039zbrPo8SblTayLasr0kFX2YUz+JifYWZL/2U8q4rkAzERH+oVVJZ1NlbgJsQ5G1yQX09BgXSXVedlLe+aCtm7KXZHc4T3Eyf3x07svvozB7QOltd2rhe6sgUfb2uExDgoHY7dqwtG3p8jaw1mGaqDH2sZQucu6L1W9zhKFJfFBks1EgdVGUET9v5oGiQM0lX0iiquM/rvs7bPk5lthdY2UaAg9oFdo2sRUej4nwJhgqcu6QnFIuLa1db11OOPIepkeurbNSU9n9NnvOk7SYFOGlRaVr6+9qaUTbtgZVtBDioXWDXyGqjUTeTafWZTxVFgeigSIBTtEGh9LUwWt0naHZCv9LKRk1tdNBNEhdAFd2PrOXzBGk+tnzVfT4n/9uH4G4KAQ5qF2wLTtoQYl/v7HxoOfEpQxQItooE6nn7vFba9Zi0T89aXOlwlr0raWXHj0vNzqNRfFSadm1WvRtrouWrDmX3K62M87mcS0CAg9r5dMNeq66HYhbly4nwrUkvZ9BXJC5rpSEjYSP3aan6aW3ijr/mc56anZMq5sXF9ANTNfiu+7jVFfRXWX9aS1jWOny4oZpCgINGeJbP6+FbRZ2ljub3qup4pNdRZqqrg3BtyU/If0dl9XQwrrMlos4h1mOp2blshV71xNXd8lVXWVLHzU2ZXvY+3FBNIcAB8vLpUcusosNc2xq2WvWRXseFZpHgpPE4rOn8V1dfkh07nPuJnyh/zhOk1rdVAoYqw998acFJ2ocqGbLu/kwdIMAB8vLwDiU1XWl30W0URlmP9DobMtRTMef5n2zBXapRbQFV5SBtNHJufj7+nJ1/fqW0NdKCU2pjU3zog1MlDWknO+96sx5pddjCTYADFOHjs7cyHUDaeNxWRwtS3x4LNm2c/47J3F5bPYqqaqxdS52bVdFVSGDhPjhVDkiRfNf1KKoywV3R4KVIEOTRzQgBDtB3ZV4W2GULTpEWJFpwYjVxWGpZZ9aoqqZHUdV189GnfFfmJqCu/cvqZE4fHAIcoJK67uAmBWWdzzuqtiD5+liwY000bNWyzqwKr8g00F3qU74rc/3XlYHSAloPziMBDtB3VZ/BTwc3dRfmdbQg+Vb5ecDbFpy0Pjhp59fHYKIv+a7M8Wu6BceTli4CHCAEVYb7NDCkN1d6y8xb0oYeVGxNxAS1rXM0KjaKyvNKsheK5tm6TravwekYAQ4wJHk6BdbxvCNvWorOPNtEGmaHOHtcYE9rIg6rdZ15V+ZbR/IeBLi1qGs/PT5eSQGORX/zz9atW92ePXu6TgbQT5s2SXv35lt2cVH6wQ8aTU5iepaWpPvvb3bbKyvS9u3SkSPHPzOLqtcZB+aWtPHY/dq4Udq1S1pebjZpg9JlHpgVlycWFqTduznpPWRmtzjnts5+vq6LxABo2L59XadgtaT0tJHOnTtXV2RSbHAjSc85uk/ORfXw9u1RPYia7NoVBRHTFhaiz9sWlyeOHIk+RzAIcIDQrKxI6wpc2gcPRnfXTdbmGzcW+7xOBYKofTqensHXdysrUb5Yt66e/LG8HLWQLC1FLWhLS921mHQZcKM1BDhASCZN70ePrv2bWfL/Nd1k0eXde1IQNXM8/kkL+jWtTs9g67tJPtq7V7U2aS0vR4+jjh2LvhcJbuoMuLoMuNEaAhwgJHFN75I0NyddfvnaIGNak00WXdy9TyrEvXvXBncLC9HxGKfnwNyS3qHd+n2tTs9g67uuH+HMBjNXXFFvwFVHwB2XxjpbvFBdXM9jH74YRQWUkDVSxeP3ydQ6SqPgBIeej4KNtDmKpcsRT2nnrs4h5lWOZ55Rit5loHApYRQVLThACCZ3k0mjIk86Kfo+eUSwtBS/3MaN9fe9yKPuRyLveld8x+LJiJ2ZliOfuofEauqRUZIuH+EU6BTe2TPEpJbSaYPvxOWBuKjHhy9acICc8txNrl+/+m4yqcmiq/lh6pwEbjTys4WqirYnyeuySSvrPVd17H/V/cubxr7mt54RLThAoPLcTT7++Oq7yaQmixtu6KbvRZ2jWtLS2kWnmrItYtP/lzSnUVMtGF02aSWco2OK6UdVtpN6Uh+jX/iFfOcobz4abCcuT8RFPT580YID5FTn3WRXfS/qbKFIOx5t94mo8v6wPDNRh/iag5h9f0wL7re1w92nJXdUNfRByrpmss4RfXC8Il7VAAQq683ORSrDrt4XVOcjkaR9WFysPdml05J1PPOc05Ar0NHI7Z+Lgpn7tOQu0ajerJjn+GZtKO71H56+yiB0BDhASKYL18XFqI9NHZVhl30v6nxnji9Dosq2iKW1MIRQgeY4142exjwtME20Wnr8Pqc+I8ABQhFXOM/PR4FOHXeTIRTCvuxD3S04HT6SquWQFnzxaqOnMWvKhLqPtU+Bd2AIcIBQeFj5IUGdfXCKVIY1zyl0eHHt46K05MRuPqvVpI78W2a/2wo8uG4bQ4ADhKLLSdiwRmadWjbYqPJ/dVXYCR1+J0FOXN2ctPnDi0vJwU0d+bfKfrfR4sd12xgCHCAU3Ak2L2eF5+VThzrzR8K67tNSYt2ctPmjyhi5VDX/pu13148sRyPn5ua4bhuSFOAwDw6gbibvLa3LF1cOQYFZg7t+ZVOsOucUSvifjYo+j5vmJXHzSpkTxiw6zlkXX9qFmrThyflraxboWWkvwO3DddurwnFGXNTjwxctOGiLl3fhWbq+Iw1ZgRYQL586JKT/8OJS8SyT0oKTdI0kHb4rF3PO7ZO04qwLNWnDXbScTF+fSdufm/Pn8VnatntQOIpHVEA8nvhglQJRi5d5J6ZSemL9gts2PypeTyX0wblycZTawTixTpytrONGVCUdwKyDnbThpECqjig0LvjIO0ljnu13HWB4mcHXIsABEnh5F47uFCjU4+qfbfPRqKNOW9dmKt4rF0fl66k8LQgzy3x1xyhfo0ORiy/PsnFpbaqSTgo+koK2MtvvOsDoSeFIgAMk6LoMgWcK3jVP16lXLo7cE+v9a9JvtJ6q0spQ5OIre6E21QqSdwbxuK+82+86wOhJ4UiAAyTouhUYHirb76HpCqFkuhpNVpWVF7n4RqO1M3avX99dP5Yibz2Xoj43cdtPS1vXAUZPCkcCHCAFfXY90MVJqHubTd5xV6hsaqmnko5V1X3Oew5Go2jG7ultzM/7N0v14mKxoC1tWR8CjB4UjgQ4APzVRUHexDbrvOOu0iE3x+oKBzdJx6qtVoauWzNmpR2TrIOddtxm96kHAUbXCHAA+KuLyquJbdYVNOUdiVNX61CWrEn02ghOu+6PEqdM8JHn3HrWidd3SQEOE/0B6F6dk9NNKzMxXJVtLi9Lu3dLS0vR5HVLS9Hvy8vF1hM3g2CSyWx7TU7Ilnas6trnLHGzCqZ93oblZen++6Vjx6LvefY5z7l1rn+T6vkoLurx4YsWnPDQ0opEdbemjEbZb6327ZHHtLwdWKcfiTTZiuLDsfKhP0odinRO7uP+dUA8okKXQimb0JA6M0jWI4CsieGS+ku0GZmndWCNS0uRAKSuxypdXMB9uEvKSmPR4eU+BNyeI8BBp3y4AYTn6qq8siqQrInhZtPURcVedLt5+6dU2Z8+BBddy3N8k5ahP05pSQGORX/zz9atW92ePXu693QOvgAAFPhJREFUTgZqsm5ddLXOMoseXwO1ScpsE0tLUX+JPDZtil7OWGUdZa2sRP019u2L+pns2pXcxyNvOrvcnyHIe3zjzu3OnZybkszsFufc1tnP6WSMVvjYPxCBSstURd/e3FTn5zyKdGDN+4b5LvdnCPIe37hzm/cc9lUHbyUnwEErQr924ZG4zCZJi4vFR/f0JTLPO5KpL/vTV1WOb1uj0bqwsiJt3x61UDkXfd++vfkgJ+65lQ9f9MEJD4/w0Zq0zFYkI/rSubas2X3dsaPd/Wn6ovetUOl7fmlKw50wRSdjoAd8K7BDU6YC6us5SdrXHTva2Z+mK3tfg4m+5pcmNTxJY1KAQyfjGhTpCwgkmjTjTk8CtrAQTjO1D4bUybbrfW16+13vH/Jr+FzRybghXT1aRIDiZjg9ciT6HPUYUifbrve16e13vX9pOuhQ67WOOmES4FREnYTa+Fxgh6JqJ9s+VVxddyhuevtd71+SpLveK67oT96pW1cdqOOeWxX9kvRaSXdKulvS+2L+/hRJnx///WZJm7LW2Zc+OD6+/w091dTLH5voD9DXfgZVJ7qLm5BtcdHP/e+6j8pQ++AkXcezlYUPaQ2EmupkLGlO0j2SzpS0XtI3Jf3MzDJXSLp2/PNbJH0+a719CXCYoRe1qbvAbqoCqPu1Cm0HSinbTE1O2gzJvlZWXQeiQxtF5Vyxd01RUdSiyQDnPEk3Tv3+fknvn1nmRknnjX8+QdIPpKiDc9JXXwIcX28i0FN1FthNRd91rdeziyczOVkVF5UVnCv2rima+muRFOBUHkVlZm+S9Frn3NvHv18m6Vzn3C9NLXPbeJkD49/vGS/zg5l1bZe0XZI2btz4s3vjel17iFFU8FJT78eoa72ejYLJTM6GDdLBg8kr4L0jkOJHQ5rFXzOM+KpFk6OoLOaz2TOZZxk553Y757Y657aefPLJNSStHUVmVAda01QnzLrW21Sn6pIdgVOTs7IiPfpo+gq67twKP8R1qL38cqZy70AdAc4BSWdM/X66pAeSljGzEyQ9U9KhGrYNhKGJ0TlNDc0su97ZfTzppPjlqgQKFeZtSI3bdu6Unngi+Z+7qKz6NKJraGbvej/+8XBfw+CzuOdWRb4U9am5V9JzdbyT8dkzy/w7re5k/IdZ6+1LHxygsib7ovgyiipuH9evd25+vt79rtA/KPU0pPW/abpza9yxrivP+NhJFyhITb6qQdKFkv5B0WiqnePPPizpdeOfT5T0BUXDxP9O0plZ6yTAwWAMYShe0j4uLtZbwVactyGxvu/qHCUFMouL1dPjWSfvNZICOwIyzGg0wGniiwAHgzGEyZTa2semApGugoEiI3Kmj+ckEJCcm5s7fgym0+tzYB13vOfno1Y/nwIyAi4vJAU4zGQMdM3XGVnr1NY+NtXvaNJxdHHx+GdPfWq1deZRtMP1unXRjLmTfkiSdPRo9H22P5LPM2fHTRH/xBPS44+v/qzLaeN5T4/3CHCArnX0npZWtbWPTU8J/8MfHv/54MHmK7SkAHBxce3xlKJg5tpr1wYHE9MBgc+BdZEgq6uAjPf0eI8AB+haV+9paVOb+9jUvA1dVGhJgeF/+k/R8ZubW/s/Lma+lWmTgKCOoDNpJFfVEV5FgqyuAjKfW8AQiXtu5cMXfXAAeKWrvlJp/TyKvBYgro9NlT4kSf2SduxI76+UZ5tl+uC03R/G5z5MAyM6GQNABT5WaEU7IdcZECRte9KpOe44FemsXWQUVRedwH0fhTYgBDgAwtDVyBUfK7Sk+YXigozpt57XsS9FW48m56uJILHLYfyMouocAQ7QRxSgq3UdZPh4PmbTlGeOnDoCgqItOEmfT4KfKqo8Pix7Tn3LC76lp0UEOJ4acJ5Elq4rcx+lVcx9uJjaSGOeyj5tmbxpLNIHZ3r9PrXglL3GfLs2fUtPywhwPDTwPIksPvb56FraYxHfL6a2Lvg8+SZtZukiaUzrE5PUYjN7Dus4BmWPbdlrzLdr07f0tIwAx0MDz5PIMoQZjpMkVZxlOrb6oq0LPk9l3+QrICay3t/V9fvR0tKYdY35dm36lp6WEeB4aOB5ElmGFgFPv14g6S4/qWJOqkilrvfquDYv+LxDsWeXqTONfci/vrfg5A3a+nCsG0SA46GB50lkGdIzzLh9Tbow4gr9pItp0qfEB3244OtMYx/yr899cIoOqff9WDeIAMdDA8+TyMPHjrNNpCnPfC5prQhprQ++BBB9uODrTqOP+XeWr6OoigabfTjWDSHA8dSA8yT6qKlKOs+cKlmBSpnAqG1dXvBFRkdRKHWPPgy5JQU4Fv3NP1u3bnV79uzpOhkApm3adPwt1dOWlqL3PtW93omFhex3VzWVthBM3nw9/S6tPMcU3SE/52Zmtzjnts5+zss2AeTX1AsG4178aBZ9z/tizr6/lb3qCyrT8Obr/ul7fvYAAQ6A/JLe3Fz1jc5xbxv/3OeiRvm8bwTv81vZJy0se/dG+7x3b/R7XUFO6G++bjI47Eqf87MneEQFID8edTSj6ccRIT/uIE8OHo+oAFTHXWUzmm5hCflxB4/fkIAAB0Axy8vRXf+xY/kfHyFdU4/+JkIOTEN//IbSCHAAoGtttLCEGpg2HRxmCbH/TyAIcACgayG3sDSty8dvTXcORyUEOADQlrS7/VBbWJrWZXBI/x+vEeAAKIem+WL6fLfv+7nuKjik/4/XCHAAFNfnyjpLU5V5X+/2r7hCuuyyMM91VV33/0EqAhwAxfW1ss7SZODWx7v9lRXp2mujYzEthHNdh5CH3weAAAdAcX2srPNoMnDr493+zp1rg5uJvp/rOtA53GsEOACK62NlnUeTgVsf7/bT9rvv57oudA73FgEOgOL6WFnn0WTg5tvdfp6+Rkn7bdb/c43gEeAAKM63yrouTQduvtzt5+1rlPSW98sv7/+5RvB42SYATFtZifqe7NsXtWDs2hVeZV7k5ZtDOB7otaSXbRLgAMDQrFsX33nYLGpdAnqEt4kDACJ5+xr5PsEfkIIABwCGJk9fo7h+Or/wC9KGDfUHOgRSaAABDgAMTZ5O4nFzAknSwYP1zmQc8qzY6BQBDgDMGkKLQtyIrun9juuEPFHnTMZdzYo9hHM8cCd0nQAA8MqkRWFS6U5aFKSwRw/N7neWumYy7mJW7KGe44FhFBUATCsyhDokSfudpK7j0cXxHuo5DhSjqAAgj1Dfs5WlyP7VOflhF7NiD/UcDwwBDgBMC/U9W1nS9m9xsblZq7uYFXuo53hgCHAAYFqo79nKkrZ/hw41+4qJtl9hMdRzPDAEOAAwLdT3bGVZXo5aauKcdFJYI46Geo4Hhk7GAIBI3Eiq9euj+WmeeOL4ZwsLBATwBp2MAQDp4lo2nv701cGN1M48NUBFBDgAgONm+8McOhS/HCOO4DkCHABAMkYcoacIcAAAyRhxhJ4iwAGAWbyn6DhGHKGneBcVAEzjPUVrLS8Pd9/RW7TgAAjfFVdIJ5wQtUCccEL0e5Ku3m4NoFa04AAI2xVXSL/7u8d/P3r0+O8f//ja5XlPERCESi04ZnaSmX3FzO4af//JhOWOmtk3xl/XV9kmABSye3exzxk1BASh6iOq90n6S+fcWZL+cvx7nB8657aMv15XcZsAkN/Ro8U+Z9QQEISqAc7rJX12/PNnJf3riusDgHrNzRX7nFFDQBCqBjg/5Zx7UJLG35+dsNyJZrbHzL5uZolBkJltHy+356GHHqqYNADQ8RFQeT+X2n+7NYDaZXYyNrO/kHRKzJ+KDCnY6Jx7wMzOlHSTmX3bOXfP7ELOud2SdkvRyzYLrB8A4k06Eu/eHT2WmpuLgpu4DsYAgpEZ4DjnXpP0NzP7RzM71Tn3oJmdKun7Cet4YPz9XjP7a0kvkrQmwAGARnz84wQ0wMBUfUR1vaS3jX9+m6Qvzi5gZj9pZk8Z/7xB0sslfafidgEAABJVDXCulvRzZnaXpJ8b/y4z22pmvzde5vmS9pjZNyX9laSrnXMEOAAAoDGVJvpzzh2UdH7M53skvX388/8r6YVVtgMAAFAEr2oAAADBIcABAFTD29fhId5FBQAoj7evw1O04AAAyuPt6/AUAQ4AoDzevg5PEeAAAMrj7evwFAEOAKA83r4OTxHgAADK4+3r8BSjqAAA1SwvE9DAO7TgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4BDgAACA4FQKcMzs583sdjM7ZmZbU5Z7rZndaWZ3m9n7qmwTAAAgS9UWnNskXSTpb5IWMLM5Sb8j6V9I+hlJl5jZz1TcLgAAQKITqvyzc+4OSTKztMVeKulu59y942X/QNLrJX2nyrYBAACStNEH5zRJ+6d+PzD+DAAAoBGZLThm9heSTon5007n3BdzbCOuecclbGu7pO2StHHjxhyrBgAAWCszwHHOvabiNg5IOmPq99MlPZCwrd2SdkvS1q1bY4MgAACALG08ovofks4ys+ea2XpJb5F0fQvbBQAAA1V1mPgbzOyApPMk/bmZ3Tj+/DlmdoMkOed+LOmXJN0o6Q5Jf+icu71asgEAAJJVHUX1p5L+NObzByRdOPX7DZJuqLItAACAvJjJGAAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABIcABwAABMecc12nIZaZPSRpb9fpkLRB0g+6TkRLhrSvEvsbsiHtqzSs/R3Svkrsbx5LzrmTZz/0NsDxhZntcc5t7TodbRjSvkrsb8iGtK/SsPZ3SPsqsb9V8IgKAAAEhwAHAAAEhwAn2+6uE9CiIe2rxP6GbEj7Kg1rf4e0rxL7Wxp9cAAAQHBowQEAAMEhwAEAAMEhwJlhZj9vZreb2TEzSxyqZmavNbM7zexuM3tfm2msi5mdZGZfMbO7xt9/MmG5o2b2jfHX9W2ns6qsc2VmTzGzz4//frOZbWo/lfXIsa/bzOyhqfP59i7SWQcz+5SZfd/Mbkv4u5nZx8bH4ltm9uK201inHPv7KjN7ZOrcfqDtNNbFzM4ws78yszvG5fG7YpYJ5vzm3N+Qzu+JZvZ3ZvbN8f7++5hlqpfLzjm+pr4kPV/S/yzpryVtTVhmTtI9ks6UtF7SNyX9TNdpL7Gv/1HS+8Y/v0/Sf0hY7rGu01phHzPPlaQrJF07/vktkj7fdbob3Ndtkq7pOq017e8rJL1Y0m0Jf79Q0pclmaSXSbq56zQ3vL+vkvRnXaezpn09VdKLxz8/XdI/xOTlYM5vzv0N6fyapKeNf56XdLOkl80sU7lcpgVnhnPuDufcnRmLvVTS3c65e51zj0v6A0mvbz51tXu9pM+Of/6spH/dYVqakudcTR+HP5J0vplZi2msSyj5Mhfn3N9IOpSyyOslXeciX5f0LDM7tZ3U1S/H/gbDOfegc+7W8c+HJd0h6bSZxYI5vzn3Nxjjc/bY+Nf58dfsiKfK5TIBTjmnSdo/9fsB9TMz/pRz7kEpusAkPTthuRPNbI+Zfd3M+hYE5TlXTy7jnPuxpEckLbaSunrlzZdvHDfp/5GZndFO0joRynVaxHnjZv8vm9nZXSemDuNHEy9SdJc/Lcjzm7K/UkDn18zmzOwbkr4v6SvOucTzW7ZcPqGOhPaNmf2FpFNi/rTTOffFPKuI+czL8fZp+1pgNRudcw+Y2ZmSbjKzbzvn7qknhY3Lc656cz4z5NmPL0n6fefcP5vZ5YrukF7deMq6Ecp5zetWRe/keczMLpT0XyWd1XGaKjGzp0n6Y0m/7Jx7dPbPMf/S6/Obsb9BnV/n3FFJW8zsWZL+1Mxe4Jyb7l9W+fwOMsBxzr2m4ioOSJq+8z1d0gMV19mItH01s380s1Odcw+Om3a/n7COB8bf7zWzv1Z0d9GXACfPuZosc8DMTpD0TPXzUUDmvjrnDk79+glJ/6GFdHWlN9dpHaYrROfcDWb2cTPb4Jzr5YsazWxeUWW/4pz7k5hFgjq/Wfsb2vmdcM49PK5XXitpOsCpXC7ziKqc/yHpLDN7rpmtV9QBqnejixSl+W3jn98maU3rlZn9pJk9ZfzzBkkvl/Sd1lJYXZ5zNX0c3iTpJjfu2dYzmfs600fhdYqe9YfqeklvHY+2eZmkRyaPZENkZqdM+iiY2UsVle8H0//LT+P9+KSkO5xzv5mwWDDnN8/+BnZ+Tx633MjMnirpNZL+fmaxyuXyIFtw0pjZGyT9tqSTJf25mX3DOXeBmT1H0u855y50zv3YzH5J0o2KRq58yjl3e4fJLutqSX9oZr8oaZ+kn5cki4bHX+6ce7uiUWX/2cyOKbqgrnbO9SbASTpXZvZhSXucc9crKlg+Z2Z3K7pDeEt3KS4v576+08xeJ+nHivZ1W2cJrsjMfl/RyJINZnZA0gcVdVaUc+5aSTcoGmlzt6Qjkv5NNymtR479fZOkHWb2Y0k/lPSWngbqUnQjdZmkb4/7aUjSr0naKAV5fvPsb0jn91RJnzWzOUX1yh865/6s7nKZVzUAAIDg8IgKAAAEhwAHAAAEhwAHAAAEhwAHAAAEhwAHAAAEhwAHAAAEhwAHAAAE5/8HYjpeDtYHTzMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(8,8))   \n",
    "\n",
    "plt.title('points in train data')\n",
    "plt.plot(data_train_point_x_class_0, data_train_point_y_class_0, 'o', color='blue', label='class = 0')\n",
    "plt.plot(data_train_point_x_class_1, data_train_point_y_class_1, 'o', color='red', label='class = 1')\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(8,8))   \n",
    "\n",
    "plt.title('points in test data')\n",
    "plt.plot(data_test_point_x_class_0, data_test_point_y_class_0, 'o', color='blue', label='class = 0')\n",
    "plt.plot(data_test_point_x_class_1, data_test_point_y_class_1, 'o', color='red', label='class = 1')\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the feature functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- feature vector is defined by $(1, f_1(x, y), f_2(x, y), \\cdots, f_{k-1}(x, y)) \\in \\mathbb{R}^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature(point):\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "\n",
    "    n = np.shape(point)[0]\n",
    "    x = point[:,0]\n",
    "    y = point[:,1]\n",
    "\n",
    "    x_square = np.power(x,2)\n",
    "    x_cubic = np.power(x,3)\n",
    "    \n",
    "    \n",
    "\n",
    "    feature = np.column_stack([np.ones(n), x, y, x_square, x_cubic])\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the linear regression function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\theta = (\\theta_0, \\theta_1, \\cdots, \\theta_{k-1}) \\in \\mathbb{R}^k$\n",
    "- feature = $(1, f_1(x, y), \\cdots, f_{k-1}(x, y)) \\in \\mathbb{R}^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_linear_regression(theta, feature):\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "\n",
    "    value = np.matmul(theta, feature.T)\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define sigmoid function with input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $z \\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "\n",
    "    value = 1 / (1 + np.exp(-z))\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    return value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the logistic regression function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\theta = (\\theta_0, \\theta_1, \\cdots, \\theta_{k-1}) \\in \\mathbb{R}^k$\n",
    "- feature $= (1, f_1(x, y), \\cdots, f_{k-1}(x, y) \\in \\mathbb{R}^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logistic_regression(theta, feature):\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "\n",
    "    value = sigmoid(compute_linear_regression(theta, feature))\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the residual function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\theta = (\\theta_0, \\theta_1, \\cdots, \\theta_{k-1}) \\in \\mathbb{R}^k$\n",
    "- feature $= (1, f_1(x, y), \\cdots, f_{k-1}(x, y) \\in \\mathbb{R}^k$\n",
    "- label $= l \\in \\{0, 1\\}^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_residual(theta, feature, label):\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "\n",
    "    h = compute_logistic_regression(theta, feature)\n",
    "    residual = (-label * np.log(h)) - ((1-label) * np.log(1-h))\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the loss function for the logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\theta = (\\theta_0, \\theta_1, \\cdots, \\theta_{k-1}) \\in \\mathbb{R}^k$\n",
    "- feature $= (1, f_1(x, y), \\cdots, f_{k-1}(x, y) \\in \\mathbb{R}^k$\n",
    "- label $= l \\in \\{0, 1\\}^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(theta, feature, label, alpha):\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "\n",
    "    residual = compute_residual(theta, feature, label)\n",
    "    loss = (np.sum(residual) / np.shape(residual)[0]) + (np.inner(theta,theta)*alpha/2)\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the gradient of the loss with respect to the model parameter $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\theta = (\\theta_0, \\theta_1, \\cdots, \\theta_{k-1}) \\in \\mathbb{R}^k$\n",
    "- feature $= (1, f_1(x, y), \\cdots, f_{k-1}(x, y) \\in \\mathbb{R}^k$\n",
    "- label $= l \\in \\{0, 1\\}^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(theta, feature, label, alpha):\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "\n",
    "    h = compute_logistic_regression(theta, feature)\n",
    "    gradient = (np.matmul(feature.T, (h-label)) / np.shape(label)[0]) + (alpha*theta)\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the accuracy of the prediction for point with a given model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(theta, feature, label):\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "    n = np.shape(feature)[0]\n",
    "    pred = np.zeros(n)\n",
    "    h = compute_logistic_regression(theta, feature)\n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        if h[i] >= 0.5:\n",
    "            pred[i] = 1\n",
    "        if pred[i] == label[i]:\n",
    "                sum += 1\n",
    "\n",
    "    accuracy = sum / n\n",
    "\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize the gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_iteration    = 10000 # you can change this value as you want \n",
    "learning_rate       = 0.7 # you can change this value as you want \n",
    "number_feature      = 5 # you can change this value as you want\n",
    "alpha               = 0.0001 # you can change this value as you want\n",
    "\n",
    "theta                       = np.zeros(number_feature)\n",
    "loss_iteration_train        = np.zeros(number_iteration)\n",
    "loss_iteration_test         = np.zeros(number_iteration)\n",
    "accuracy_iteration_train    = np.zeros(number_iteration)\n",
    "accuracy_iteration_test     = np.zeros(number_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the gradient descent algorithm to optimize the loss function with respect to the model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for i in range(number_iteration):\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    " \n",
    "    theta           = theta - learning_rate*compute_gradient(theta, compute_feature(data_train_point), data_train_label, alpha)\n",
    "    loss_train      = compute_loss(theta, compute_feature(data_train_point), data_train_label, alpha)\n",
    "    loss_test       = compute_loss(theta, compute_feature(data_test_point), data_test_label, alpha)\n",
    "    accuracy_train  = compute_accuracy(theta, compute_feature(data_train_point), data_train_label)\n",
    "    accuracy_test   = compute_accuracy(theta, compute_feature(data_test_point), data_test_label)\n",
    "\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    loss_iteration_train[i]     = loss_train\n",
    "    loss_iteration_test[i]      = loss_test\n",
    "    accuracy_iteration_train[i] = accuracy_train\n",
    "    accuracy_iteration_test[i]  = accuracy_test\n",
    "\n",
    "theta_optimal = theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iteration    = 3000 # you can change this value as you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_alpha = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001]\n",
    "ex_learning_rate = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001]\n",
    "len(ex_alpha), len(ex_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_learning = []\n",
    "num_alpha = []\n",
    "final_loss_train        = []\n",
    "final_loss_test         = []\n",
    "final_accuracy_train    = []\n",
    "final_accuracy_test     = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate =  1\n",
      "alpha =  1\n",
      "final training loss = 34.3319696278\n",
      "final training accuracy =  0.4920000000\n",
      "final testing loss = 32.9773559536\n",
      "final testing accuracy =  0.4960000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nextgen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "/home/nextgen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate =  1\n",
      "alpha =  0.9\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.5820000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.5700000000\n",
      "learning_rate =  1\n",
      "alpha =  0.8\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7020000000\n",
      "learning_rate =  1\n",
      "alpha =  0.7\n",
      "final training loss =  8.1098685757\n",
      "final training accuracy =  0.5000000000\n",
      "final testing loss =  7.7866706565\n",
      "final testing accuracy =  0.5000000000\n",
      "learning_rate =  1\n",
      "alpha =  0.6\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6020000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.5960000000\n",
      "learning_rate =  1\n",
      "alpha =  0.5\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6620000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6540000000\n",
      "learning_rate =  1\n",
      "alpha =  0.4\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6820000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6640000000\n",
      "learning_rate =  1\n",
      "alpha =  0.3\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7100000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7040000000\n",
      "learning_rate =  1\n",
      "alpha =  0.2\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7160000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7100000000\n",
      "learning_rate =  1\n",
      "alpha =  0.1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7180000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7100000000\n",
      "learning_rate =  1\n",
      "alpha =  0.05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7200000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1\n",
      "alpha =  0.01\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7620000000\n",
      "learning_rate =  1\n",
      "alpha =  0.005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7420000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7180000000\n",
      "learning_rate =  1\n",
      "alpha =  0.001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8760000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8560000000\n",
      "learning_rate =  1\n",
      "alpha =  0.0005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8140000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8080000000\n",
      "learning_rate =  1\n",
      "alpha =  0.0001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8620000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8380000000\n",
      "learning_rate =  1\n",
      "alpha =  5e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8780000000\n",
      "learning_rate =  1\n",
      "alpha =  1e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8600000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8440000000\n",
      "learning_rate =  1\n",
      "alpha =  5e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9100000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8820000000\n",
      "learning_rate =  1\n",
      "alpha =  1e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8680000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8460000000\n",
      "learning_rate =  0.9\n",
      "alpha =  1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.5860000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.5720000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.9\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7040000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.8\n",
      "final training loss = 10.7031214133\n",
      "final training accuracy =  0.5000000000\n",
      "final testing loss = 10.2742575750\n",
      "final testing accuracy =  0.5000000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.7\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6020000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6000000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.6\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6440000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6380000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.5\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6700000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6660000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.4\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6920000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6980000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.3\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7160000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7040000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.2\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7020000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7220000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7020000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7120000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.01\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7620000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7140000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8380000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8140000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8620000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.0005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8860000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8740000000\n",
      "learning_rate =  0.9\n",
      "alpha =  0.0001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8280000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8380000000\n",
      "learning_rate =  0.9\n",
      "alpha =  5e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8380000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8420000000\n",
      "learning_rate =  0.9\n",
      "alpha =  1e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9040000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8780000000\n",
      "learning_rate =  0.9\n",
      "alpha =  5e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8960000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8660000000\n",
      "learning_rate =  0.9\n",
      "alpha =  1e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8360000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8360000000\n",
      "learning_rate =  0.8\n",
      "alpha =  1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7020000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.9\n",
      "final training loss =  9.5156795122\n",
      "final training accuracy =  0.5000000000\n",
      "final testing loss =  9.1365631066\n",
      "final testing accuracy =  0.5000000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.8\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6180000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6260000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.7\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6440000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6340000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.6\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6820000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6760000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.5\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6840000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6820000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.4\n",
      "final training loss =  9.5780658768\n",
      "final training accuracy =  0.5000000000\n",
      "final testing loss =  9.1877588565\n",
      "final testing accuracy =  0.5000000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.3\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7180000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7200000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.2\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6820000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7160000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7220000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7180000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.01\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8240000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8020000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8320000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7940000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8040000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7900000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.0005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8740000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8660000000\n",
      "learning_rate =  0.8\n",
      "alpha =  0.0001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8660000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8440000000\n",
      "learning_rate =  0.8\n",
      "alpha =  5e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8960000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8740000000\n",
      "learning_rate =  0.8\n",
      "alpha =  1e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8720000000\n",
      "learning_rate =  0.8\n",
      "alpha =  5e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8880000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8680000000\n",
      "learning_rate =  0.8\n",
      "alpha =  1e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8420000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8380000000\n",
      "learning_rate =  0.7\n",
      "alpha =  1\n",
      "final training loss =  5.7165144879\n",
      "final training accuracy =  0.5000000000\n",
      "final testing loss =  5.4953768789\n",
      "final testing accuracy =  0.5000000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.9\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6200000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6280000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.8\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6580000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6460000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.7\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6840000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6800000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.6\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6820000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6780000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.5\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7000000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.4\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7140000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7040000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.3\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7200000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.2\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7220000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7020000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7160000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7080000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7220000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.01\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7280000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7120000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8440000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8200000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8840000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8660000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.0005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8820000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8640000000\n",
      "learning_rate =  0.7\n",
      "alpha =  0.0001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8420000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8280000000\n",
      "learning_rate =  0.7\n",
      "alpha =  5e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8340000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8340000000\n",
      "learning_rate =  0.7\n",
      "alpha =  1e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9120000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8840000000\n",
      "learning_rate =  0.7\n",
      "alpha =  5e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8460000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8380000000\n",
      "learning_rate =  0.7\n",
      "alpha =  1e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8440000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8280000000\n",
      "learning_rate =  0.6\n",
      "alpha =  1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6500000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6400000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.9\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6800000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6640000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.8\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6980000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.7\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6920000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6900000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.6\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7000000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.5\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7160000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7040000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.4\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7040000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.3\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7100000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6960000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.2\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6560000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6560000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7220000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7120000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6840000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.01\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7720000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7460000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8860000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8420000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9100000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8720000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.0005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8880000000\n",
      "learning_rate =  0.6\n",
      "alpha =  0.0001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8740000000\n",
      "learning_rate =  0.6\n",
      "alpha =  5e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8660000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8460000000\n",
      "learning_rate =  0.6\n",
      "alpha =  1e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8500000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8400000000\n",
      "learning_rate =  0.6\n",
      "alpha =  5e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8760000000\n",
      "learning_rate =  0.6\n",
      "alpha =  1e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8860000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8520000000\n",
      "learning_rate =  0.5\n",
      "alpha =  1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6960000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.9\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6860000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6900000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.8\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6960000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7020000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.7\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6980000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.6\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7020000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.5\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7100000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.4\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7160000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7080000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.3\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6980000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.2\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7120000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7200000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7540000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.01\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8680000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8380000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7820000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7520000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8180000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8300000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.0005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8800000000\n",
      "learning_rate =  0.5\n",
      "alpha =  0.0001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8900000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8660000000\n",
      "learning_rate =  0.5\n",
      "alpha =  5e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8540000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8420000000\n",
      "learning_rate =  0.5\n",
      "alpha =  1e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8760000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8460000000\n",
      "learning_rate =  0.5\n",
      "alpha =  5e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8740000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8440000000\n",
      "learning_rate =  0.5\n",
      "alpha =  1e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8760000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8480000000\n",
      "learning_rate =  0.4\n",
      "alpha =  1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7000000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.9\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6980000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7040000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.8\n",
      "final training loss =  4.4225398440\n",
      "final training accuracy =  0.5000000000\n",
      "final testing loss =  4.2559057375\n",
      "final testing accuracy =  0.5000000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.7\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7140000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7000000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.6\n",
      "final training loss =  3.6040233329\n",
      "final training accuracy =  0.5000000000\n",
      "final testing loss =  3.4675581988\n",
      "final testing accuracy =  0.5000000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.5\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7160000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7080000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.4\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6980000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6820000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.3\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7240000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7120000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.2\n",
      "final training loss =  0.6901406360\n",
      "final training accuracy =  0.6760000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6600000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7220000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6940000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7620000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7660000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.01\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8380000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8020000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7980000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7820000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8860000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8720000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.0005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8700000000\n",
      "learning_rate =  0.4\n",
      "alpha =  0.0001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8860000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8540000000\n",
      "learning_rate =  0.4\n",
      "alpha =  5e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8860000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8540000000\n",
      "learning_rate =  0.4\n",
      "alpha =  1e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8880000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8520000000\n",
      "learning_rate =  0.4\n",
      "alpha =  5e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8880000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8520000000\n",
      "learning_rate =  0.4\n",
      "alpha =  1e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8740000000\n",
      "learning_rate =  0.3\n",
      "alpha =  1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7020000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.9\n",
      "final training loss =  2.6269105687\n",
      "final training accuracy =  0.5000000000\n",
      "final testing loss =  2.5340058918\n",
      "final testing accuracy =  0.5000000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.8\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7160000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.7\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7180000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7160000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.6\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7100000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7000000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.5\n",
      "final training loss =  0.7449337405\n",
      "final training accuracy =  0.6260000000\n",
      "final testing loss =  0.7573148122\n",
      "final testing accuracy =  0.6160000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.4\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.6900000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.6740000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.3\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7220000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7040000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.2\n",
      "final training loss =  0.6268003030\n",
      "final training accuracy =  0.6640000000\n",
      "final testing loss =  0.6461887488\n",
      "final testing accuracy =  0.6600000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.1\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7460000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7620000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7780000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7820000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.01\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8680000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8480000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9020000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8660000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8860000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8740000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.0005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8920000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8800000000\n",
      "learning_rate =  0.3\n",
      "alpha =  0.0001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9020000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8760000000\n",
      "learning_rate =  0.3\n",
      "alpha =  5e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9000000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8760000000\n",
      "learning_rate =  0.3\n",
      "alpha =  1e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8560000000\n",
      "learning_rate =  0.3\n",
      "alpha =  5e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8540000000\n",
      "learning_rate =  0.3\n",
      "alpha =  1e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8540000000\n",
      "learning_rate =  0.2\n",
      "alpha =  1\n",
      "final training loss =  0.7712028916\n",
      "final training accuracy =  0.5940000000\n",
      "final testing loss =  0.7770723772\n",
      "final testing accuracy =  0.5820000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.9\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7140000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7080000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.8\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7180000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7040000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.7\n",
      "final training loss =  0.9414676940\n",
      "final training accuracy =  0.5240000000\n",
      "final testing loss =  0.9302432415\n",
      "final testing accuracy =  0.5240000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.6\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7100000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.5\n",
      "final training loss =  0.6334693037\n",
      "final training accuracy =  0.6560000000\n",
      "final testing loss =  0.6470192826\n",
      "final testing accuracy =  0.6540000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.4\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7160000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7180000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.3\n",
      "final training loss =  0.5297352072\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7100000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.2\n",
      "final training loss =  0.6735061896\n",
      "final training accuracy =  0.5860000000\n",
      "final testing loss =  0.6803161883\n",
      "final testing accuracy =  0.5800000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.1\n",
      "final training loss =  0.4780477775\n",
      "final training accuracy =  0.7740000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.05\n",
      "final training loss =  0.4900275958\n",
      "final training accuracy =  0.7460000000\n",
      "final testing loss =  0.5106147374\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.01\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8760000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8460000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8800000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8540000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9040000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8800000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.0005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9100000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8860000000\n",
      "learning_rate =  0.2\n",
      "alpha =  0.0001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8860000000\n",
      "learning_rate =  0.2\n",
      "alpha =  5e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9000000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8760000000\n",
      "learning_rate =  0.2\n",
      "alpha =  1e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9000000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8780000000\n",
      "learning_rate =  0.2\n",
      "alpha =  5e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8860000000\n",
      "learning_rate =  0.2\n",
      "alpha =  1e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9020000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8780000000\n",
      "learning_rate =  0.1\n",
      "alpha =  1\n",
      "final training loss =  0.5964137947\n",
      "final training accuracy =  0.7380000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7360000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.9\n",
      "final training loss =  0.5815820231\n",
      "final training accuracy =  0.7320000000\n",
      "final testing loss =  0.5904654742\n",
      "final testing accuracy =  0.7100000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.8\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.7420000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7340000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.7\n",
      "final training loss =  0.5522683650\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5650014287\n",
      "final testing accuracy =  0.7420000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.6\n",
      "final training loss =  0.5390113856\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5520053475\n",
      "final testing accuracy =  0.7440000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.5\n",
      "final training loss =  0.5396133252\n",
      "final training accuracy =  0.7540000000\n",
      "final testing loss =  0.5521776374\n",
      "final testing accuracy =  0.7240000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.4\n",
      "final training loss =  0.5368202429\n",
      "final training accuracy =  0.7540000000\n",
      "final testing loss =  0.5495166784\n",
      "final testing accuracy =  0.7280000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.3\n",
      "final training loss =  0.5410285272\n",
      "final training accuracy =  0.7500000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.2\n",
      "final training loss =  0.5228534063\n",
      "final training accuracy =  0.7620000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.7700000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.1\n",
      "final training loss =  0.4837065600\n",
      "final training accuracy =  0.7820000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8020000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.05\n",
      "final training loss =  0.4417282262\n",
      "final training accuracy =  0.8160000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8220000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.01\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8800000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9020000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8860000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9040000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8860000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.0005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8860000000\n",
      "learning_rate =  0.1\n",
      "alpha =  0.0001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8840000000\n",
      "learning_rate =  0.1\n",
      "alpha =  5e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8860000000\n",
      "learning_rate =  0.1\n",
      "alpha =  1e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8860000000\n",
      "learning_rate =  0.1\n",
      "alpha =  5e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8860000000\n",
      "learning_rate =  0.1\n",
      "alpha =  1e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8860000000\n",
      "learning_rate =  0.05\n",
      "alpha =  1\n",
      "final training loss =  0.5503069767\n",
      "final training accuracy =  0.7340000000\n",
      "final testing loss =  0.5613773539\n",
      "final testing accuracy =  0.7420000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.9\n",
      "final training loss =  0.5475291240\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5587959085\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.8\n",
      "final training loss =  0.5442568594\n",
      "final training accuracy =  0.7380000000\n",
      "final testing loss =  0.5557473662\n",
      "final testing accuracy =  0.7480000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.7\n",
      "final training loss =  0.5403327893\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5520804110\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.6\n",
      "final training loss =  0.5355206210\n",
      "final training accuracy =  0.7480000000\n",
      "final testing loss =  0.5475667151\n",
      "final testing accuracy =  0.7540000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.5\n",
      "final training loss =  0.5294451086\n",
      "final training accuracy =  0.7520000000\n",
      "final testing loss =  0.5418417167\n",
      "final testing accuracy =  0.7540000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.4\n",
      "final training loss =  0.5214627747\n",
      "final training accuracy =  0.7660000000\n",
      "final testing loss =  0.5342769276\n",
      "final testing accuracy =  0.7520000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.3\n",
      "final training loss =  0.5103391255\n",
      "final training accuracy =  0.7720000000\n",
      "final testing loss =  0.5236615675\n",
      "final testing accuracy =  0.7660000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.2\n",
      "final training loss =  0.4932326362\n",
      "final training accuracy =  0.7880000000\n",
      "final testing loss =  0.5072076162\n",
      "final testing accuracy =  0.7800000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.1\n",
      "final training loss =  0.4607562682\n",
      "final training accuracy =  0.8080000000\n",
      "final testing loss =  0.4758008534\n",
      "final testing accuracy =  0.8240000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.05\n",
      "final training loss =  0.4250084723\n",
      "final training accuracy =  0.8340000000\n",
      "final testing loss =  0.4414653153\n",
      "final testing accuracy =  0.8420000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.01\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8940000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8800000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.8980000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8820000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9040000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8880000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.0005\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9060000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8880000000\n",
      "learning_rate =  0.05\n",
      "alpha =  0.0001\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8880000000\n",
      "learning_rate =  0.05\n",
      "alpha =  5e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8880000000\n",
      "learning_rate =  0.05\n",
      "alpha =  1e-05\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8880000000\n",
      "learning_rate =  0.05\n",
      "alpha =  5e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8880000000\n",
      "learning_rate =  0.05\n",
      "alpha =  1e-06\n",
      "final training loss =           nan\n",
      "final training accuracy =  0.9080000000\n",
      "final testing loss =           nan\n",
      "final testing accuracy =  0.8880000000\n",
      "learning_rate =  0.01\n",
      "alpha =  1\n",
      "final training loss =  0.5503069767\n",
      "final training accuracy =  0.7340000000\n",
      "final testing loss =  0.5613773539\n",
      "final testing accuracy =  0.7420000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.9\n",
      "final training loss =  0.5475291240\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5587959085\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.8\n",
      "final training loss =  0.5442568594\n",
      "final training accuracy =  0.7380000000\n",
      "final testing loss =  0.5557473662\n",
      "final testing accuracy =  0.7480000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.7\n",
      "final training loss =  0.5403327893\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5520804110\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.6\n",
      "final training loss =  0.5355206210\n",
      "final training accuracy =  0.7480000000\n",
      "final testing loss =  0.5475667151\n",
      "final testing accuracy =  0.7540000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.5\n",
      "final training loss =  0.5294451086\n",
      "final training accuracy =  0.7520000000\n",
      "final testing loss =  0.5418417166\n",
      "final testing accuracy =  0.7540000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.4\n",
      "final training loss =  0.5214627747\n",
      "final training accuracy =  0.7660000000\n",
      "final testing loss =  0.5342769262\n",
      "final testing accuracy =  0.7520000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.3\n",
      "final training loss =  0.5103391256\n",
      "final training accuracy =  0.7720000000\n",
      "final testing loss =  0.5236615312\n",
      "final testing accuracy =  0.7660000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.2\n",
      "final training loss =  0.4932326565\n",
      "final training accuracy =  0.7880000000\n",
      "final testing loss =  0.5072065262\n",
      "final testing accuracy =  0.7800000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.1\n",
      "final training loss =  0.4607727301\n",
      "final training accuracy =  0.8080000000\n",
      "final testing loss =  0.4757720067\n",
      "final testing accuracy =  0.8240000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.05\n",
      "final training loss =  0.4256348250\n",
      "final training accuracy =  0.8200000000\n",
      "final testing loss =  0.4416888371\n",
      "final testing accuracy =  0.8380000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.01\n",
      "final training loss =  0.3590062546\n",
      "final training accuracy =  0.8500000000\n",
      "final testing loss =  0.3769873133\n",
      "final testing accuracy =  0.8560000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.005\n",
      "final training loss =  0.3443119521\n",
      "final training accuracy =  0.8560000000\n",
      "final testing loss =  0.3626946572\n",
      "final testing accuracy =  0.8560000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.001\n",
      "final training loss =  0.3307086557\n",
      "final training accuracy =  0.8580000000\n",
      "final testing loss =  0.3494553048\n",
      "final testing accuracy =  0.8580000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.0005\n",
      "final training loss =  0.3288756845\n",
      "final training accuracy =  0.8580000000\n",
      "final testing loss =  0.3476708071\n",
      "final testing accuracy =  0.8580000000\n",
      "learning_rate =  0.01\n",
      "alpha =  0.0001\n",
      "final training loss =  0.3273865035\n",
      "final training accuracy =  0.8600000000\n",
      "final testing loss =  0.3462209106\n",
      "final testing accuracy =  0.8580000000\n",
      "learning_rate =  0.01\n",
      "alpha =  5e-05\n",
      "final training loss =  0.3271989100\n",
      "final training accuracy =  0.8600000000\n",
      "final testing loss =  0.3460382597\n",
      "final testing accuracy =  0.8580000000\n",
      "learning_rate =  0.01\n",
      "alpha =  1e-05\n",
      "final training loss =  0.3270486022\n",
      "final training accuracy =  0.8600000000\n",
      "final testing loss =  0.3458919110\n",
      "final testing accuracy =  0.8580000000\n",
      "learning_rate =  0.01\n",
      "alpha =  5e-06\n",
      "final training loss =  0.3270297992\n",
      "final training accuracy =  0.8600000000\n",
      "final testing loss =  0.3458736032\n",
      "final testing accuracy =  0.8580000000\n",
      "learning_rate =  0.01\n",
      "alpha =  1e-06\n",
      "final training loss =  0.3270147544\n",
      "final training accuracy =  0.8600000000\n",
      "final testing loss =  0.3458589546\n",
      "final testing accuracy =  0.8580000000\n",
      "learning_rate =  0.005\n",
      "alpha =  1\n",
      "final training loss =  0.5503069767\n",
      "final training accuracy =  0.7340000000\n",
      "final testing loss =  0.5613773538\n",
      "final testing accuracy =  0.7420000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.9\n",
      "final training loss =  0.5475291240\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5587959084\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.8\n",
      "final training loss =  0.5442568594\n",
      "final training accuracy =  0.7380000000\n",
      "final testing loss =  0.5557473657\n",
      "final testing accuracy =  0.7480000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.7\n",
      "final training loss =  0.5403327893\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5520804081\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.6\n",
      "final training loss =  0.5355206210\n",
      "final training accuracy =  0.7480000000\n",
      "final testing loss =  0.5475667002\n",
      "final testing accuracy =  0.7540000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.5\n",
      "final training loss =  0.5294451094\n",
      "final training accuracy =  0.7520000000\n",
      "final testing loss =  0.5418416376\n",
      "final testing accuracy =  0.7540000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.4\n",
      "final training loss =  0.5214627965\n",
      "final training accuracy =  0.7660000000\n",
      "final testing loss =  0.5342764999\n",
      "final testing accuracy =  0.7520000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.3\n",
      "final training loss =  0.5103397136\n",
      "final training accuracy =  0.7720000000\n",
      "final testing loss =  0.5236594014\n",
      "final testing accuracy =  0.7640000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.2\n",
      "final training loss =  0.4932503267\n",
      "final training accuracy =  0.7880000000\n",
      "final testing loss =  0.5072054355\n",
      "final testing accuracy =  0.7800000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.1\n",
      "final training loss =  0.4614389798\n",
      "final training accuracy =  0.8060000000\n",
      "final testing loss =  0.4762765685\n",
      "final testing accuracy =  0.8080000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.05\n",
      "final training loss =  0.4304871837\n",
      "final training accuracy =  0.8120000000\n",
      "final testing loss =  0.4459922658\n",
      "final testing accuracy =  0.8240000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.01\n",
      "final training loss =  0.3864217161\n",
      "final training accuracy =  0.8180000000\n",
      "final testing loss =  0.4027428370\n",
      "final testing accuracy =  0.8320000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.005\n",
      "final training loss =  0.3787611566\n",
      "final training accuracy =  0.8180000000\n",
      "final testing loss =  0.3952153346\n",
      "final testing accuracy =  0.8340000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.001\n",
      "final training loss =  0.3721551560\n",
      "final training accuracy =  0.8180000000\n",
      "final testing loss =  0.3887225993\n",
      "final testing accuracy =  0.8340000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.0005\n",
      "final training loss =  0.3712974092\n",
      "final training accuracy =  0.8180000000\n",
      "final testing loss =  0.3878794663\n",
      "final testing accuracy =  0.8340000000\n",
      "learning_rate =  0.005\n",
      "alpha =  0.0001\n",
      "final training loss =  0.3706059035\n",
      "final training accuracy =  0.8180000000\n",
      "final testing loss =  0.3871997270\n",
      "final testing accuracy =  0.8340000000\n",
      "learning_rate =  0.005\n",
      "alpha =  5e-05\n",
      "final training loss =  0.3705191311\n",
      "final training accuracy =  0.8180000000\n",
      "final testing loss =  0.3871144302\n",
      "final testing accuracy =  0.8340000000\n",
      "learning_rate =  0.005\n",
      "alpha =  1e-05\n",
      "final training loss =  0.3704496596\n",
      "final training accuracy =  0.8180000000\n",
      "final testing loss =  0.3870461399\n",
      "final testing accuracy =  0.8340000000\n",
      "learning_rate =  0.005\n",
      "alpha =  5e-06\n",
      "final training loss =  0.3704409723\n",
      "final training accuracy =  0.8180000000\n",
      "final testing loss =  0.3870376003\n",
      "final testing accuracy =  0.8340000000\n",
      "learning_rate =  0.005\n",
      "alpha =  1e-06\n",
      "final training loss =  0.3704340219\n",
      "final training accuracy =  0.8180000000\n",
      "final testing loss =  0.3870307681\n",
      "final testing accuracy =  0.8340000000\n",
      "learning_rate =  0.001\n",
      "alpha =  1\n",
      "final training loss =  0.5503252685\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5613804219\n",
      "final testing accuracy =  0.7440000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.9\n",
      "final training loss =  0.5475657562\n",
      "final training accuracy =  0.7340000000\n",
      "final testing loss =  0.5588105938\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.8\n",
      "final training loss =  0.5443309637\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5557897261\n",
      "final testing accuracy =  0.7440000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.7\n",
      "final training loss =  0.5404845891\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5521861236\n",
      "final testing accuracy =  0.7460000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.6\n",
      "final training loss =  0.5358366142\n",
      "final training accuracy =  0.7440000000\n",
      "final testing loss =  0.5478155016\n",
      "final testing accuracy =  0.7460000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.5\n",
      "final training loss =  0.5301170942\n",
      "final training accuracy =  0.7500000000\n",
      "final testing loss =  0.5424151133\n",
      "final testing accuracy =  0.7460000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.4\n",
      "final training loss =  0.5229351300\n",
      "final training accuracy =  0.7500000000\n",
      "final testing loss =  0.5356031836\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.3\n",
      "final training loss =  0.5137136863\n",
      "final training accuracy =  0.7500000000\n",
      "final testing loss =  0.5268143659\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.2\n",
      "final training loss =  0.5015844933\n",
      "final training accuracy =  0.7500000000\n",
      "final testing loss =  0.5151955474\n",
      "final testing accuracy =  0.7500000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.1\n",
      "final training loss =  0.4852160459\n",
      "final training accuracy =  0.7500000000\n",
      "final testing loss =  0.4994351503\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.05\n",
      "final training loss =  0.4748325169\n",
      "final training accuracy =  0.7540000000\n",
      "final testing loss =  0.4894002612\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.01\n",
      "final training loss =  0.4651627487\n",
      "final training accuracy =  0.7560000000\n",
      "final testing loss =  0.4800344297\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.005\n",
      "final training loss =  0.4638568714\n",
      "final training accuracy =  0.7560000000\n",
      "final testing loss =  0.4787682394\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.001\n",
      "final training loss =  0.4627955160\n",
      "final training accuracy =  0.7560000000\n",
      "final testing loss =  0.4777389164\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.0005\n",
      "final training loss =  0.4626617914\n",
      "final training accuracy =  0.7560000000\n",
      "final testing loss =  0.4776092138\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.001\n",
      "alpha =  0.0001\n",
      "final training loss =  0.4625546418\n",
      "final training accuracy =  0.7560000000\n",
      "final testing loss =  0.4775052845\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.001\n",
      "alpha =  5e-05\n",
      "final training loss =  0.4625412375\n",
      "final training accuracy =  0.7560000000\n",
      "final testing loss =  0.4774922829\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.001\n",
      "alpha =  1e-05\n",
      "final training loss =  0.4625305123\n",
      "final training accuracy =  0.7560000000\n",
      "final testing loss =  0.4774818799\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.001\n",
      "alpha =  5e-06\n",
      "final training loss =  0.4625291715\n",
      "final training accuracy =  0.7560000000\n",
      "final testing loss =  0.4774805794\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.001\n",
      "alpha =  1e-06\n",
      "final training loss =  0.4625280989\n",
      "final training accuracy =  0.7560000000\n",
      "final testing loss =  0.4774795391\n",
      "final testing accuracy =  0.7560000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  1\n",
      "final training loss =  0.5509687458\n",
      "final training accuracy =  0.7280000000\n",
      "final testing loss =  0.5618071774\n",
      "final testing accuracy =  0.7380000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.9\n",
      "final training loss =  0.5485042427\n",
      "final training accuracy =  0.7280000000\n",
      "final testing loss =  0.5594824018\n",
      "final testing accuracy =  0.7400000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.8\n",
      "final training loss =  0.5457063586\n",
      "final training accuracy =  0.7340000000\n",
      "final testing loss =  0.5568362260\n",
      "final testing accuracy =  0.7400000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.7\n",
      "final training loss =  0.5425109154\n",
      "final training accuracy =  0.7340000000\n",
      "final testing loss =  0.5538058316\n",
      "final testing accuracy =  0.7440000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.6\n",
      "final training loss =  0.5388389680\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5503138154\n",
      "final testing accuracy =  0.7380000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.5\n",
      "final training loss =  0.5345930125\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5462644257\n",
      "final testing accuracy =  0.7380000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.4\n",
      "final training loss =  0.5296521456\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5415387544\n",
      "final testing accuracy =  0.7380000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.3\n",
      "final training loss =  0.5238658685\n",
      "final training accuracy =  0.7480000000\n",
      "final testing loss =  0.5359885793\n",
      "final testing accuracy =  0.7380000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.2\n",
      "final training loss =  0.5170461320\n",
      "final training accuracy =  0.7480000000\n",
      "final testing loss =  0.5294284550\n",
      "final testing accuracy =  0.7400000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.1\n",
      "final training loss =  0.5089570979\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5216255290\n",
      "final testing accuracy =  0.7400000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.05\n",
      "final training loss =  0.5043466506\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5171691244\n",
      "final testing accuracy =  0.7360000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.01\n",
      "final training loss =  0.5003479009\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5132993083\n",
      "final testing accuracy =  0.7360000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.005\n",
      "final training loss =  0.4998273029\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5127951976\n",
      "final testing accuracy =  0.7340000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.001\n",
      "final training loss =  0.4994073855\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5123885303\n",
      "final testing accuracy =  0.7340000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.0005\n",
      "final training loss =  0.4993546794\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5123374843\n",
      "final testing accuracy =  0.7340000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  0.0001\n",
      "final training loss =  0.4993124798\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5122966133\n",
      "final testing accuracy =  0.7340000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  5e-05\n",
      "final training loss =  0.4993072026\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5122915023\n",
      "final testing accuracy =  0.7340000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  1e-05\n",
      "final training loss =  0.4993029806\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5122874132\n",
      "final testing accuracy =  0.7340000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  5e-06\n",
      "final training loss =  0.4993024528\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5122869020\n",
      "final testing accuracy =  0.7340000000\n",
      "learning_rate =  0.0005\n",
      "alpha =  1e-06\n",
      "final training loss =  0.4993020306\n",
      "final training accuracy =  0.7400000000\n",
      "final testing loss =  0.5122864931\n",
      "final testing accuracy =  0.7340000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  1\n",
      "final training loss =  0.5647992391\n",
      "final training accuracy =  0.7340000000\n",
      "final testing loss =  0.5741357522\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.9\n",
      "final training loss =  0.5642113943\n",
      "final training accuracy =  0.7340000000\n",
      "final testing loss =  0.5735685111\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.8\n",
      "final training loss =  0.5636041947\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5729822784\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.7\n",
      "final training loss =  0.5629767892\n",
      "final training accuracy =  0.7380000000\n",
      "final testing loss =  0.5723762115\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.6\n",
      "final training loss =  0.5623282854\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5717494270\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.5\n",
      "final training loss =  0.5616577475\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5711009982\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.4\n",
      "final training loss =  0.5609641940\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5704299532\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.3\n",
      "final training loss =  0.5602465957\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5697352722\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.2\n",
      "final training loss =  0.5595038727\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5690158854\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.1\n",
      "final training loss =  0.5587348922\n",
      "final training accuracy =  0.7380000000\n",
      "final testing loss =  0.5682706701\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.05\n",
      "final training loss =  0.5583401861\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5678880109\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.01\n",
      "final training loss =  0.5580193783\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5675769204\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.005\n",
      "final training loss =  0.5579789577\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5675377195\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.001\n",
      "final training loss =  0.5579465696\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5675063081\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.0005\n",
      "final training loss =  0.5579425179\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5675023785\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  0.0001\n",
      "final training loss =  0.5579392760\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5674992343\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  5e-05\n",
      "final training loss =  0.5579388708\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5674988412\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  1e-05\n",
      "final training loss =  0.5579385465\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5674985268\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  5e-06\n",
      "final training loss =  0.5579385060\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5674984875\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  0.0001\n",
      "alpha =  1e-06\n",
      "final training loss =  0.5579384736\n",
      "final training accuracy =  0.7360000000\n",
      "final testing loss =  0.5674984560\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  1\n",
      "final training loss =  0.5720056927\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5808621246\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.9\n",
      "final training loss =  0.5717466948\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5806120113\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.8\n",
      "final training loss =  0.5714839643\n",
      "final training accuracy =  0.7280000000\n",
      "final testing loss =  0.5803582280\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.7\n",
      "final training loss =  0.5712174205\n",
      "final training accuracy =  0.7280000000\n",
      "final testing loss =  0.5801006946\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.6\n",
      "final training loss =  0.5709469806\n",
      "final training accuracy =  0.7280000000\n",
      "final testing loss =  0.5798393287\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.5\n",
      "final training loss =  0.5706725597\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5795740462\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.4\n",
      "final training loss =  0.5703940708\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5793047608\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.3\n",
      "final training loss =  0.5701114249\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5790313839\n",
      "final testing accuracy =  0.7300000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.2\n",
      "final training loss =  0.5698245306\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5787538248\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.1\n",
      "final training loss =  0.5695332944\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5784719906\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.05\n",
      "final training loss =  0.5693860182\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5783294406\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.01\n",
      "final training loss =  0.5692673902\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5782146058\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.005\n",
      "final training loss =  0.5692525109\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5782002014\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.001\n",
      "final training loss =  0.5692405993\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5781886699\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.0005\n",
      "final training loss =  0.5692391098\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5781872279\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  0.0001\n",
      "final training loss =  0.5692379182\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5781860743\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  5e-05\n",
      "final training loss =  0.5692377692\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5781859301\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  1e-05\n",
      "final training loss =  0.5692376500\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5781858147\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  5e-06\n",
      "final training loss =  0.5692376351\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5781858003\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  5e-05\n",
      "alpha =  1e-06\n",
      "final training loss =  0.5692376232\n",
      "final training accuracy =  0.7300000000\n",
      "final testing loss =  0.5781857888\n",
      "final testing accuracy =  0.7320000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  1\n",
      "final training loss =  0.5812736637\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5893872587\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.9\n",
      "final training loss =  0.5811801895\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5892963216\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.8\n",
      "final training loss =  0.5810864111\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5892050807\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.7\n",
      "final training loss =  0.5809923270\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5891135342\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.6\n",
      "final training loss =  0.5808979355\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5890216806\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.5\n",
      "final training loss =  0.5808032350\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5889295182\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.4\n",
      "final training loss =  0.5807082240\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5888370455\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.3\n",
      "final training loss =  0.5806129007\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5887442607\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.2\n",
      "final training loss =  0.5805172636\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5886511623\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.1\n",
      "final training loss =  0.5804213110\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5885577485\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.05\n",
      "final training loss =  0.5803732158\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5885109229\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.01\n",
      "final training loss =  0.5803346824\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5884734051\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.005\n",
      "final training loss =  0.5803298622\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5884687119\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.001\n",
      "final training loss =  0.5803260054\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5884649566\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.0005\n",
      "final training loss =  0.5803255233\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5884644872\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  0.0001\n",
      "final training loss =  0.5803251376\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5884641116\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  5e-05\n",
      "final training loss =  0.5803250894\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5884640647\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  1e-05\n",
      "final training loss =  0.5803250508\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5884640271\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  5e-06\n",
      "final training loss =  0.5803250460\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5884640225\n",
      "final testing accuracy =  0.7060000000\n",
      "learning_rate =  1e-05\n",
      "alpha =  1e-06\n",
      "final training loss =  0.5803250421\n",
      "final training accuracy =  0.7120000000\n",
      "final testing loss =  0.5884640187\n",
      "final testing accuracy =  0.7060000000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ex_learning_rate)):\n",
    "    for j in range(len(ex_alpha)):\n",
    "\n",
    "        theta                       = np.zeros(number_feature)\n",
    "\n",
    "        for k in range(number_iteration):\n",
    "            theta           = theta - ex_learning_rate[i]*compute_gradient(theta, compute_feature(data_train_point), data_train_label, ex_alpha[j])\n",
    "            #loss_train      = compute_loss(theta, compute_feature(data_train_point), data_train_label, alpha)\n",
    "            #loss_test       = compute_loss(theta, compute_feature(data_test_point), data_test_label, alpha)\n",
    "            #accuracy_train  = compute_accuracy(theta, compute_feature(data_train_point), data_train_label)\n",
    "            #accuracy_test   = compute_accuracy(theta, compute_feature(data_test_point), data_test_label)\n",
    "\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "            #loss_iteration_train[i]     = loss_train\n",
    "            #loss_iteration_test[i]      = loss_test\n",
    "            #accuracy_iteration_train[i] = accuracy_train\n",
    "            #accuracy_iteration_test[i]  = accuracy_test\n",
    "\n",
    "        loss_train      = compute_loss(theta, compute_feature(data_train_point), data_train_label, ex_alpha[j])\n",
    "        loss_test       = compute_loss(theta, compute_feature(data_test_point), data_test_label, ex_alpha[j])\n",
    "        accuracy_train  = compute_accuracy(theta, compute_feature(data_train_point), data_train_label)\n",
    "        accuracy_test   = compute_accuracy(theta, compute_feature(data_test_point), data_test_label)\n",
    "        num_learning.append(ex_learning_rate[i])\n",
    "        num_alpha.append(ex_alpha[j])\n",
    "        final_loss_train.append(loss_train)\n",
    "        final_loss_test.append(loss_test)\n",
    "        final_accuracy_train.append(accuracy_train)\n",
    "        final_accuracy_test.append(accuracy_test)\n",
    "        print('learning_rate = ', ex_learning_rate[i])\n",
    "        print('alpha = ', ex_alpha[j])\n",
    "        print(\"final training loss = {:13.10f}\".format(loss_train))\n",
    "        print(\"final training accuracy = {:13.10f}\".format(accuracy_train))\n",
    "        print(\"final testing loss = {:13.10f}\".format(loss_test))\n",
    "        print(\"final testing accuracy = {:13.10f}\".format(accuracy_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions for presenting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_01():\n",
    "\n",
    "    print(\"final training accuracy = {:13.10f}\".format(accuracy_iteration_train[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_02():\n",
    "\n",
    "    print(\"final testing accuracy = {:13.10f}\".format(accuracy_iteration_test[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_03():\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title('training loss')\n",
    "\n",
    "    plt.plot(loss_iteration_train, '-', color='red')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('loss')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_04():\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title('testing loss')\n",
    "\n",
    "    plt.plot(loss_iteration_test, '-', color='red')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('loss')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_05():\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title('training accuracy')\n",
    "\n",
    "    plt.plot(accuracy_iteration_train, '-', color='red')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_06():\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title('testing accuracy')\n",
    "\n",
    "    plt.plot(accuracy_iteration_test, '-', color='red')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the linear regression values over the 2-dimensional Euclidean space and superimpose the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_07():\n",
    "\n",
    "    plt.figure(figsize=(8,8)) \n",
    "    plt.title('linear regression values on the training data')\n",
    "    \n",
    "    min_x   = np.min(data_train_point_x)\n",
    "    max_x   = np.max(data_train_point_x)\n",
    "    min_y   = np.min(data_train_point_y)\n",
    "    max_y   = np.max(data_train_point_y)\n",
    "\n",
    "    X = np.arange(min_x - 0.5, max_x + 0.5, 0.1) \n",
    "    Y = np.arange(min_y - 0.5, max_y + 0.5, 0.1) \n",
    "\n",
    "    [XX, YY] = np.meshgrid(X, Y)\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    plt.plot(data_train_point_x_class_0, data_train_point_y_class_0, '.', color='blue', label='class = 0')\n",
    "    plt.plot(data_train_point_x_class_1, data_train_point_y_class_1, '.', color='red', label='class = 1')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_08():\n",
    "    \n",
    "    plt.figure(figsize=(8,8)) \n",
    "    plt.title('linear regression values on the testing data')\n",
    "    \n",
    "    min_x   = np.min(data_test_point_x)\n",
    "    max_x   = np.max(data_test_point_x)\n",
    "    min_y   = np.min(data_test_point_y)\n",
    "    max_y   = np.max(data_test_point_y)\n",
    "\n",
    "    X = np.arange(min_x - 0.5, max_x + 0.5, 0.1)\n",
    "    Y = np.arange(min_y - 0.5, max_y + 0.5, 0.1) \n",
    "\n",
    "    [XX, YY] = np.meshgrid(X, Y)\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    plt.plot(data_test_point_x_class_0, data_test_point_y_class_0, '.', color='blue', label='class = 0')\n",
    "    plt.plot(data_test_point_x_class_1, data_test_point_y_class_1, '.', color='red', label='class = 1')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the logistic regression values over the 2-dimensional Euclidean space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_09():\n",
    "\n",
    "    plt.figure(figsize=(8,8)) \n",
    "    plt.title('logistic regression values on the training data')\n",
    "    \n",
    "    min_x   = np.min(data_train_point_x)\n",
    "    max_x   = np.max(data_train_point_x)\n",
    "    min_y   = np.min(data_train_point_y)\n",
    "    max_y   = np.max(data_train_point_y)\n",
    "\n",
    "    X = np.arange(min_x - 0.5, max_x + 0.5, 0.1) \n",
    "    Y = np.arange(min_y - 0.5, max_y + 0.5, 0.1) \n",
    "\n",
    "    [XX, YY] = np.meshgrid(X, Y)\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "    plt.plot(data_train_point_x_class_0, data_train_point_y_class_0, '.', color='blue', label='class = 0')\n",
    "    plt.plot(data_train_point_x_class_1, data_train_point_y_class_1, '.', color='red', label='class = 1')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_10():\n",
    "    \n",
    "    plt.figure(figsize=(8,8)) \n",
    "    plt.title('logistic regression values on the testing data')\n",
    "\n",
    "    min_x   = np.min(data_test_point_x)\n",
    "    max_x   = np.max(data_test_point_x)\n",
    "    min_y   = np.min(data_test_point_y)\n",
    "    max_y   = np.max(data_test_point_y)\n",
    "\n",
    "    X = np.arange(min_x - 0.5, max_x + 0.5, 0.1) \n",
    "    Y = np.arange(min_y - 0.5, max_y + 0.5, 0.1) \n",
    "\n",
    "    [XX, YY] = np.meshgrid(X, Y)\n",
    "\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # complete the blanks\n",
    "    #\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    # ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "    plt.plot(data_test_point_x_class_0, data_test_point_y_class_0, '.', color='blue', label='class = 0')\n",
    "    plt.plot(data_test_point_x_class_1, data_test_point_y_class_1, '.', color='red', label='class = 1')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "## [RESULT 01]\n",
      "**************************************************\n",
      "final training accuracy =  0.9160000000\n",
      "**************************************************\n",
      "## [RESULT 02]\n",
      "**************************************************\n",
      "final testing accuracy =  0.9020000000\n",
      "**************************************************\n",
      "## [RESULT 03]\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "## [RESULT 04]\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "## [RESULT 05]\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "## [RESULT 06]\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "## [RESULT 07]\n",
      "**************************************************\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'function_result_07' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-2846470133c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'**************************************************'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'function_result_07' is not defined"
     ]
    }
   ],
   "source": [
    "number_result = 10\n",
    "\n",
    "for i in range(number_result):\n",
    "    title = '## [RESULT {:02d}]'.format(i+1)\n",
    "    name_function = 'function_result_{:02d}()'.format(i+1)\n",
    "\n",
    "    print('**************************************************')\n",
    "    print(title)\n",
    "    print('**************************************************')\n",
    "    eval(name_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
